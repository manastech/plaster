"""
Plaster-specific plots

These fall into two categories:
    * Mature: plots that are ready to be used in notebook report templates
    * Development: Plots that are still being worked on across various notebooks

Note:
    * All plots are free-functions
    * All plots should accept a run parameters and *optional* modifications to
      the default plot.
    * Naming conventions:
        def text_* dump information as print statements
        def plot_* are plots
        def wizard_* are interactive wizard-type components that may have plot components
    * bokeh imports should be deferred (they tend to slow down tests)
"""
from collections import defaultdict

from munch import Munch

import numpy as np
import pandas as pd
from plaster.run.call_bag import CallBag
from plaster.run.lnfit.lnfit_result import LNFitResult
from plaster.tools.image import imops
from plaster.tools.image.coord import WH, XY
from plaster.tools.ipynb_helpers import displays
from plaster.tools.ipynb_helpers.displays import hd, md
from plaster.tools.log.log import debug, info
from plaster.tools.schema import check
from plaster.tools.utils import data, utils
from plaster.tools.zplots.zplots import ZPlots
from scipy.stats import iqr

# Mature
# ====================================================================================================


# Prep & sim related
# -----------------------


def text_prep_and_sim_info(run):
    """
    State statistics about labelling and sim including
    protein identifiability under the labelling scheme.

    Audience:
        Basic users

    Goal:
        Allow the user to understand the experimental setup
        and the high-level overview of the label space.
    """

    n_train_non_zero_recall_peps = (run.sim.train_recalls > 0.0).sum()
    n_train_zero_recall_peps = (run.sim.train_recalls == 0.0).sum()
    n_train_peps = n_train_non_zero_recall_peps + n_train_zero_recall_peps

    n_test_non_zero_recall_peps = (run.sim.test_recalls > 0.0).sum()
    n_test_zero_recall_peps = (run.sim.test_recalls == 0.0).sum()
    n_test_peps = n_test_non_zero_recall_peps + n_test_zero_recall_peps

    print(
        f"The preparation consisted of:\n"
        f"  Proteins: {len(run.prep.pros()) - 1}.\n"
        f"    Of which: {len(run.prep.pros__from_decoys())} are decoys generated by the {run.prep.params.decoy_mode} method.\n"
        f"  Labels: {run.sim.params.to_label_str()}.\n"
        f"  Protease: {run.prep.params.protease} including {run.prep.params.include_misses} missed cleavages.\n"
        f"  Peptides: {len(run.prep.peps()) - 1}.\n"
        f"    Unique: {len(run.prep.pepstrs().seqstr.drop_duplicates()) - 1}\n"
        f"    From real sources: {len(run.prep.peps__no_decoys()) - 1}\n"
        f"    From decoy sources: {len(run.prep.peps__from_decoys())}\n"
        f"Simulation was run with:\n"
        f"  n_pres: {run.sim.params.n_pres}, n_mocks: {run.sim.params.n_mocks}, n_edmans: {run.sim.params.n_edmans}\n"
        f"  Train set:\n"
        f"    {n_train_non_zero_recall_peps} ({100 * n_train_non_zero_recall_peps / n_train_peps:2.0f}%) have positive recall (observable)\n"
        f"    {n_train_zero_recall_peps} ({100 * n_train_zero_recall_peps / n_train_peps:2.0f}%) had zero recall (unlabelable)\n"
        f"  Test set:\n"
        f"    {n_test_non_zero_recall_peps} ({100 * n_test_non_zero_recall_peps / n_test_peps:2.0f}%) have positive recall (observable)\n"
        f"    {n_test_zero_recall_peps} ({100 * n_test_zero_recall_peps / n_test_peps:2.0f}%) had zero recall (unlabelable)\n"
    )

    # TODO: if the run has a "protein of interest" then repeat a lot of the above for
    # just the protein of interest -- e.g. how many peptides, unique, positive recall, etc.
    if (
        run.prep.n_pros_of_interest > 0 and run.prep.n_pros > 2
    ):  # ==2 means 1 protein and the 'null' entry
        pro_ids = run.prep.pros__in_report().pro_id
        pep_iz = run.prep.peps__in_report().pep_i.unique()
        pepstrs = run.prep.pepstrs()
        pepstrs = pepstrs[pepstrs.pep_i.isin(pep_iz)]

        print(
            f"\n\n"
            f"Protein(s) of interest: {list(pro_ids)}\n"
            f"  Peptides: {len(pep_iz)}\n"
            f"    Unique: {len(pepstrs.seqstr.drop_duplicates())}\n"
            f"  TODO: more stats on just this protein(s)\n"
        )


# Classification related
# -----------------------


def text_call_score_info(run, classifier=None):
    """
    State statistics about classification.

    Audience:
        Advanced users

    Goal:
        Allow the user to see:
            How many uniq FluoroSeqs, PeptideSeqs, and ProteinSeqs were called true and pred.
            How many real vs decoys were called with counts

    classifier: None to use any available preferred classifier, or one of the
                supported classifiers in RunResult::test_call_bag(), e.g. 'rf', 'nn'

    """

    bag = run.test_call_bag(classifier=classifier)
    n_zeros = (bag.pred_pep_iz == 0).sum()

    pred = bag.pred_peps__pros()
    n_pred_real = (pred.pro_is_decoy < 1).sum()
    n_pred_decoy = (pred.pro_is_decoy > 0).sum()
    n_preds = len(pred)

    print(
        f"Test {bag.classifier_name.upper()} classification result has {bag.n_rows} rows.\n"
        f"  Of which: {n_zeros} were predicted to empty.\n"
        f"True calls came from:\n"
        f"  {len(bag.true_peps__pros())} samples over {bag.true_peps__pros().groupby('pep_i').ngroups} total peptides of which {len(bag.true_peps__unique())} were unique\n"
        f"Predicted calls went to:\n"
        f"  {len(bag.pred_peps__pros())} samples covering {len(bag.pred_peps__unique())} unique peptides\n"
        f"  {100.0 * n_pred_real / n_preds:2.0f}% reals and {100.0 * n_pred_decoy / n_preds:2.0f}% decoys\n"
    )


def pep_iz_in_report(run, with_ptms=False):
    if with_ptms:
        return run.prep.peps__ptms(
            in_report_only=True, ptms_to_rows=False
        ).pep_i.unique()
    return run.prep.peps__in_report().pep_i.values


def plot_peptide_effective_labelability(run, **kwargs):
    """
    'effective labelability' means how often does a peptide result in a dye-track signature that is
    non-zero.  A 'zero' signature might occur because the peptide detaches immediately, a dye
    is a dud, a dye bleaches immediately (in a mock cycle), or, most typically, that the peptide
    has no amino acids that can be labeled.  The latter is 'unlabelable'.  All the others are
    'effectively unlabelable'

    I am using the name 'labelability' because the next fn in this file plots observability vs
    precision, and it is confusing to use the word observability for both plots.  I have also
    considered "scope_observability" vs "classifier_observability".  The confusion arises when
    you look at the plot produced by this function, which looks only at "train recalls", and see
    that 100%, or nearly 100%, of peptides are "observable".  And then in the next set of plots
    which look at PR for peptides, you see that only 80% of the peptides are observable even at
    precision=0.  How can this be?  It is because even if a peptide has labels and produces a
    non-zero dye-track (so it is "scope observable" or "labelable"), it may NEVER get picked
    by the classifier because some other peptide class receives a higher score.  So in our
    "post classification" notion of PR, even at precision 0, the peptide is not observable
    by the classifier.

    Y axis is the fraction 'scope' observable, or 'effectively labelable'
    X axis is rank ordered peptides where peptide with highest “frac observable” is on the left.
    Some of the peptides will have zero observability, we call those by the special name “unlabelable”

    Up to three plots may be displayed:
    1. All peptides the classifier will be trained on
    2. Only peptides belonging to any "protein_of_interest"; see set_protein_of_interest()
    3. Only peptides satisfying (2) and additionally containing PTM locations

    Goal:
        Allow user to see:
            What portion/how well the peptides can be "seen" given the current labelling scheme.
    """

    pep_iz_poi = pep_iz_in_report(run, with_ptms=False)
    pep_iz_ptm = pep_iz_in_report(run, with_ptms=True)

    pep_indices = [np.array(range(1, run.sim.train_recalls.shape[0]))]
    if len(pep_iz_poi):
        pep_indices.append(np.sort(pep_iz_poi))
    if len(pep_iz_ptm):
        pep_indices.append(np.sort(pep_iz_ptm))

    z = kwargs.get("_zplots_context", ZPlots())
    with z(
        _cols=len(pep_indices),
        f_y_axis_label="per-class fraction labelable",
        f_x_axis_label="peptide class rank",
        f_y_range=(0, 1),
        **kwargs,
    ):

        for idx, domain in zip(pep_indices, ["", "POI ", "PTM "]):
            train_recalls = run.sim.train_recalls[idx]

            train_recalls_sorted = np.sort(train_recalls)[::-1]
            n_classes = len(train_recalls_sorted)
            n_observable = np.sum(train_recalls_sorted.astype(bool))
            z.cols(
                train_recalls_sorted,
                f_title=f"{domain}{n_observable} of {n_classes} ({100.0 * n_observable / n_classes:,.1f}%) peptides labelable",
            )


def plot_peptides_per_fluorosequence(run, **kwargs):
    peps__flus = (
        run.sim.peps__flus(run.prep)
        .drop_duplicates("flustr")
        .sort_values("flu_count", ascending=False)
        .reset_index()
    )
    labels = peps__flus.apply(lambda x: f"{x.flustr} ({x.flu_count})", axis=1)
    z = kwargs.pop("_zplot_context", ZPlots())
    # Note 1: below -- we are not showing the unlabeled peptides.
    z.cols(
        peps__flus.flu_count.values[1:],
        _label=labels.values[1:],
        _size_x=1000,
        f_title="(Labelable) Peptides per fluorosequence",
        f_x_axis_label="fluorsequence class rank",
        f_y_axis_label="peptide count",
        **kwargs,
    )


def _plot_peptide_observability_vs_precision(
    pr_df, pep_iz=None, as_fraction_observable=True, pr_axes=True, **kwargs
):
    """
    given a precision-recall information for a set of peptides, plot
    the fraction of those pep_i observable as a function of precision.

    pr_df:                  a df that contains precision,recall values for each pep_i
    pep_iz:                 the subset of pep_i to consider, or None or all pep_i
    as_fraction_observable: when True show observability as fraction of total peptides
    pr_axes:                when True orient the plot as standard PR plots, with PEPTIDE
                            recall on the x-axis.

    Y axis is number of classes or fraction of classes observable at precision X
    X axis is precision

    Goal:
        Answer question:
            How many of the peptide classes can I observe at precision X?
            (or, equivalently)
            At precision X, how many peptide classes have a recall > 0?
    """

    pep_iz_with_pr = list(pr_df.pep_i.unique())

    #     no_pr = [pi  for pi in pep_iz if pi not in pep_iz_with_pr ]
    #     print(no_pr)

    assert pep_iz is None or all(
        [pi in pep_iz_with_pr for pi in pep_iz]
    ), "pr_df must contain PR info for all pep_iz"

    if pep_iz is None:
        pep_iz = pep_iz_with_pr

    pr_by_pep = pr_df[pr_df.pep_i.isin(pep_iz)]

    n_peps_at_precision = []
    precisions = np.linspace(0, 1, 51)
    for prec in precisions:
        peps_observable_at_prec = pr_by_pep[
            (pr_by_pep.prec >= prec) & (pr_by_pep.recall > 0)
        ].pep_i.unique()
        n_peps_at_precision += [len(peps_observable_at_prec)]

    n_classes = len(pep_iz)

    y_range = (0, n_classes)
    if as_fraction_observable:
        n_peps_at_precision = np.array(n_peps_at_precision) / n_classes
        y_range = (0, 1.05)
    x_range = (0, 1.05)

    y_axis = (
        "fraction of classes observable"
        if as_fraction_observable
        else "peptide classes observable"
    )
    x_axis = "precision"

    y_values = n_peps_at_precision
    x_values = precisions

    if not pr_axes:  # because this was the default for a long time
        args = dict(
            x=x_values,
            y=y_values,
            f_x_axis_label=x_axis,
            f_y_axis_label=y_axis,
            f_x_range=x_range,
            f_y_range=y_range,
        )
    else:
        args = dict(
            y=x_values,
            x=y_values,
            f_y_axis_label=x_axis,
            f_x_axis_label="peptide-classes recall",
            f_y_range=x_range,
            f_x_range=y_range,
        )

    z = kwargs.get("_zplots_context", None) or ZPlots()
    z.line(**args, **kwargs, line_width=2)


def plot_peptide_observability_vs_precision(
    run,
    pep_iz=None,
    as_fraction_observable=True,
    pr_axes=True,
    classifier=None,
    **kwargs,
):
    """
    See docs at _plot_peptide_observability_vs_precision()

    This fn calls that one 1-3 times to plot various peptide subsets

    pr_style_axes: If True, orient the axes as a standard PR plot, with PEPTIDE
                   recall on the x-axis.  Otherwise, interpret as
                   "peptide observability vs precision"

    classifier: None to use any available preferred classifier, or one of the
                supported classifiers in RunResult::test_call_bag(), e.g. 'rf', 'nn'
    """
    bag = run.test_call_bag(classifier=classifier)
    pr_by_pep_all = bag.pr_curve_by_pep()

    pep_iz_all = list(pr_by_pep_all.pep_i.unique())
    pep_iz_poi = pep_iz_in_report(run, with_ptms=False)
    pep_iz_ptm = pep_iz_in_report(run, with_ptms=True)

    if pep_iz is not None and len(pep_iz) > 0:
        pep_iz_all = [pi for pi in pep_iz_all if pi in pep_iz]
        pep_iz_poi = [pi for pi in pep_iz_poi if pi in pep_iz]
        pep_iz_ptm = [pi for pi in pep_iz_ptm if pi in pep_iz]

    pep_iz_sets = [pep_iz_all]
    if len(pep_iz_poi):
        pep_iz_sets.append(np.sort(pep_iz_poi))
    if len(pep_iz_ptm):
        pep_iz_sets.append(np.sort(pep_iz_ptm))

    z = kwargs.pop("_zplots_context", None) or ZPlots()
    zargs = dict(_cols=len(pep_iz_sets)) if len(pep_iz_sets) > 1 else dict()
    with z(**zargs):
        for _pep_iz, domain in zip(pep_iz_sets, ["", "POI ", "PTM "]):
            vs_text = (
                "Peptide-Classes PR"
                if pr_axes
                else "Peptide Observability vs Precision"
            )
            title = f"{bag.classifier_name.upper()} {domain}{vs_text}, {len(_pep_iz)} classes"
            _plot_peptide_observability_vs_precision(
                pr_by_pep_all,
                _pep_iz,
                as_fraction_observable=as_fraction_observable,
                pr_axes=pr_axes,
                f_title=title,
                _zplots_context=z,
                **kwargs,
            )


def plot_call_score_hist(run, classifier=None, **kwargs):
    """
    Demonstrate an overview of classification scores for predictions to non-decoy versus decoys.

    Audience:
        Advanced users

    Goal:
        Allow the user to see:
            if the decoy and real false rates have roughly equal distributions
            if high scores are a good predictor of correctness.

    Plan:
        This is probably not a long-term useful plot as the imposter map
        will probably communicate most of this information in a more useful way.

    classifier: None to use any available preferred classifier, or one of the
                supported classifiers in RunResult::test_call_bag(), e.g. 'rf', 'nn'
    """

    bag = run.test_call_bag(classifier=classifier)

    z = kwargs.pop("_zplots_context", None) or ZPlots()
    with z(
        _bins=np.linspace(0, 1, 20),
        _merge=True,
        line_alpha=1,
        f_plot_width=500,
        f_plot_height=250,
        f_x_range=(0, 1),
        f_y_range=(0, 0.9),
        f_x_axis_label="Score",
        f_y_axis_label="Count",
        f_title=f"Normalized distribution of call scores - {bag.classifier_name.upper()}",
        _step=True,
        _legend_click_policy="hide",
    ):

        correct_mask = bag.true_pep_iz == bag.pred_pep_iz
        real_mask = bag.pred_peps__pros().pro_is_decoy < 1
        decoy_mask = bag.pred_peps__pros().pro_is_decoy > 0
        mask = correct_mask & real_mask

        if np.any(mask):
            z.hist(
                bag.scores[mask],
                _normalizer=mask.sum(),
                line_color=ZPlots.feature,
                line_width=3,
                legend_label="Correct calls predicted to an any-real source",
            )

        wrong_mask = ~correct_mask
        mask = wrong_mask & real_mask
        if np.any(mask):
            z.hist(
                bag.scores[mask],
                _normalizer=mask.sum(),
                line_color=ZPlots.compare1,
                line_width=2,
                line_dash=[2, 2],
                legend_label="Wrong calls predicted to an any-real source",
            )

        if np.any(decoy_mask):
            z.hist(
                bag.scores[mask],
                _normalizer=decoy_mask.sum(),
                line_color=ZPlots.compare2,
                line_width=2,
                line_dash=[5, 3],
                legend_label="Any calls predicted to an any-decoy source",
            )


def _plot_pr_curve(prsa, **kwargs):
    """
    Plot one pr curve.

    Note that the pr_curve might have a very large number of points
    and this makes the plotting slow. The information at the top (high prec)
    is usually more interesting so we sample from the set logarithmically.

    Arguments:
        prsa: a 4-tuple of precision, recall, min_score, AUC generated by AssignmentEval.pr_curve or similar.

    TASK
        I want this to have hover tools but I need to sort out hovers using zplots.
        But I also need this to be zplot mergable so for now I'm taking out the hover.
    """

    check.affirm(len(prsa) == 4)
    check.list_or_tuple_t(prsa[0:2], np.ndarray)
    n_rows = prsa[0].shape[0]
    check.array_t(prsa[0], (n_rows,))
    check.array_t(prsa[1], (n_rows,))

    n_prs = len(prsa[0])
    if n_prs <= 1:
        info(f"Unable to show plot of pr_curve with n_prs of {n_prs}")
        return

    kwargs = utils.set_defaults(kwargs, line_width=2, line_alpha=1.0, _noise=0.000)

    # Add noise to keep them from sitting on top of each other
    # An _noise of about 0.005 is typically sufficient if any is needed
    _noise = kwargs.pop("_noise")
    x_noise = np.random.uniform(-_noise, +_noise, size=n_rows)
    y_noise = np.random.uniform(-_noise, +_noise, size=n_rows)

    z = kwargs.get("_zplots_context", None) or ZPlots()
    z.line(
        x=prsa[1] + x_noise,
        y=prsa[0] + y_noise,
        _range=(0, 1.05, 0, 1.05),
        f_x_axis_label="read recall",
        f_y_axis_label="precision",
        f_title=kwargs.pop("f_title", "Precision-Recall"),
        **kwargs,
    )


def plot_pr_aggregate(run, pep_iz=None, classifier=None, **kwargs):
    """
    Show P/R for all some set aggregate set of peptides
    (ie. renders a single line for the set. See also: plot_pr_breakout)

    Arguments:
        pep_iz: If None computes over all peps, otherwise the subset
        classifier: None to use any available preferred classifier, or one of the
                    supported classifiers in RunResult::test_call_bag(), e.g. 'rf', 'nn'
        kwargs: Passed to the zplot

    Audience:
        Trained users.
        P/R curves will not be familiar to many customers but it is an important concept to teach
        as it is central to the way we treat evidence.

    Goal:
        Allow user to see:
            The P/R curve for ALL peptides as an aggregate statistic

    Plan:
        There's a lot of way to look at this and it probably needs
        to be subdivided into separate curves or made into an interactive widget.

        In general, I'm going to avoid having lots of switches on this
        and instead rely on with z.Opts(_merge=True) when the need to be overlaid.
    """
    cb = run.test_call_bag(classifier=classifier)
    prsa = cb.pr_curve(pep_iz_subset=pep_iz)
    utils.set_defaults(
        kwargs, f_title=f"{cb.classifier_name.upper()} P/R over all peptides"
    )
    _plot_pr_curve(prsa, **kwargs)


def plot_pr_breakout(run, pep_iz=None, classifier=None, **kwargs):
    """
    Render a separate P/R curve for each pep_iz.
    See plot_pr_aggregate()

    Arguments:
        If pep_iz is None it renders ALL peptides. (Might be large!)
        classifier: None to use any available preferred classifier, or one of the
                    supported classifiers in RunResult::test_call_bag(), e.g. 'rf', 'nn'

        kwargs: passed to zplot
    """
    master_bag = run.test_call_bag(classifier=classifier)

    if pep_iz is None:
        pep_iz = list(range(1, run.prep.n_peps))

    utils.set_defaults(
        kwargs, f_title=f"{master_bag.classifier_name.upper()} P/R over all peptides"
    )
    z = kwargs.pop("_zplots_context", None) or ZPlots()
    user_color = kwargs.get("color", None)
    with z(
        _merge=True,
        _range=(0, 1.05, 0, 1.05),
        f_x_axis_label="read recall",
        f_y_axis_label="precision",
        _zplots_context=z,
        **kwargs,
    ):
        pr_df = master_bag.pr_curve_by_pep(pep_iz=pep_iz)
        for pep_i, g in pr_df.groupby("pep_i"):
            prsa = (g.prec.values, g.recall.values, g.score.values, [])
            # for pep_i in pep_iz:
            #     prsa = master_bag.pr_curve_by_pep(pep_iz_subset=[pep_i])
            _plot_pr_curve(
                prsa,
                line_color=user_color or z.next(),
                _label=pep_i,
                _zplots_context=z,
                **kwargs,
            )

            # this will only get plotted if all class scores are available:
            prsa = master_bag.pr_curve_sklearn(pep_i)
            if prsa[0] is not None:
                _plot_pr_curve(prsa, _zplots_context=z, line_width=1, **kwargs)


def plot_pr_for_run(
    run, aggregate_only=False, force_all_proteins=False, classifier=None, **kwargs
):
    """
    Display one or more PR plots depending on the config of run.

    Plot aggregate and breakout PRs for protein(s) of interest if any are set,
    otherwise plot aggregate of all proteins/peptides.

    Note that individual PR curves are not plotted if the number of peptides exceeds
    some value (currently 50) because of some slowdown in notebooks when there are
    lots of individual curves.  This slowdown needs to be investigated - it should be
    able to do hundreds without any issue.  Right?

    aggregate_only: Do not plot PR curves for any individual peptides, whether the domain
                    is all proteins, or proteins of interest, or proteins with PTMs.

    force_all_proteins: Plot PR for *all* proteins (always an aggregate PR) even if there
                        are proteins-of-interest specified for this run.

    classifier: None to use any available preferred classifier, or one of the
                supported classifiers in RunResult::test_call_bag(), e.g. 'rf', 'nn'

    kwargs: passed to zplot

    NOTE: in my experience, aggregate PR curves are not very informative.
    """

    z = kwargs.pop("_zplots_context", None) or ZPlots()
    zOpts = {} if aggregate_only or run.prep.n_pros_of_interest == 0 else {"_cols": 3}

    with z(**zOpts):
        z.color_reset()

        # *Up to* three columns, if we have interesting domains to look at.
        if run.prep.n_pros_of_interest > 0 and not force_all_proteins:
            pep_iz = run.prep.peps__in_report().pep_i.unique()
            n_peps = len(pep_iz)
            if n_peps > 1 or aggregate_only:
                plot_pr_aggregate(
                    run,
                    pep_iz=pep_iz,
                    classifier=classifier,
                    f_title=f"{classifier.upper()} Aggregate PR ({n_peps} peptides of interest)",
                    _zplots_context=z,
                    **kwargs,
                )
            # maybe do breakout of individual peps of interest
            if not aggregate_only:
                if n_peps < 50:  # See comment at top.
                    plot_pr_breakout(
                        run,
                        pep_iz=pep_iz,
                        classifier=classifier,
                        f_title=f"{classifier.upper()} Individual PR ({n_peps} peptides of interest)",
                        _zplots_context=z,
                        **kwargs,
                    )
                else:
                    info(
                        f"Individual peptide PR for protein-of-interest skipped because plot with {n_peps} peptides may be slow."
                    )

            # maybe do breakout of peps of interest that have PTM locations
            df = run.prep.peps__ptms(in_report_only=True, ptms_to_rows=False)
            pep_w_ptm_iz = df.pep_i.values
            n_peps_w_ptm = len(pep_w_ptm_iz)
            if n_peps_w_ptm > 0 and not aggregate_only and n_peps_w_ptm != n_peps:
                if n_peps_w_ptm < 50:  # See comment at top.
                    plot_pr_breakout(
                        run,
                        pep_iz=pep_w_ptm_iz,
                        classifier=classifier,
                        f_title=f"{classifier.upper()} Individual PR ({n_peps_w_ptm} peptides w PTMs)",
                        _zplots_context=z,
                        **kwargs,
                    )
                else:
                    info(
                        f"Individual PTM-peptide PR skipped because plot with {n_peps_w_ptm} peptides may be slow."
                    )

        else:
            # All proteins, less the "null" entry at 0
            n_peps = run.prep.n_peps - 1
            n_pros = run.prep.n_pros - 1
            plot_pr_aggregate(
                run,
                classifier=classifier,
                f_title=f"{classifier.upper()} Aggregate PR ({n_pros} proteins, {n_peps} peptides)",
                _zplots_context=z,
                **kwargs,
            )


def plot_pr_for_job(job, force_all_proteins=False, classifier="rf", **kwargs):
    """
    Single plot containing relevant PR per run, with legend to indicate run.

    force_all_proteins: Plot PR for *all* proteins (aggregate) even if there
                        are proteins-of-interest specified for this run.

    classifier: None to use any available preferred classifier, or one of the
                supported classifiers in RunResult::test_call_bag(), e.g. 'rf', 'nn'

    kwargs: passed to zplot
    """

    domain = f"all proteins, observable peptides per run"

    run = job.runs[0]  # get proteins_of_interest, same for each run
    if run.prep.n_pros_of_interest > 0 and not force_all_proteins:
        domain = f"{run.prep.n_pros_of_interest} protein(s) of interest, observable peptides per run"

    from bokeh.palettes import Category20

    palette = Category20[20]

    z = ZPlots()
    with z(
        _merge=True,
        f_title=f"PR all runs, {domain}",
        f_x_axis_label="read recall",
        f_y_axis_label="precision",
    ):
        for i, run in enumerate(job.runs):
            color = palette[i % 20]
            name = "_".join(run.run_name.split("_")[:-1])
            plot_pr_for_run(
                run,
                aggregate_only=True,
                force_all_proteins=force_all_proteins,
                classifier=classifier,
                color=color,
                legend_label=name,
                _zplots_context=z,
                **kwargs,
            )


def standard_run_report(run, display_run_title=True, classifier=None):

    if display_run_title:
        hd("h2", f"Run: {run.run_name}")

    # Information from Prep and Simulation that has nothing
    # to do with classification
    hd("h3", f"Prep and simulation")
    text_prep_and_sim_info(run)
    plot_peptide_effective_labelability(run)
    plot_peptides_per_fluorosequence(run)

    # If no classifier is specified, print information from all available
    # classifiers, otherwise just the one that was requested.
    hd("h3", f"Classification")
    classifiers = run.get_available_classifiers()
    if classifier in classifiers:
        classifiers = [classifier]

    # Do textual information on classifiers one after the other.
    for classifier in classifiers:
        text_call_score_info(run, classifier=classifier)

    z = ZPlots()

    # Do call/score histograms next to each other
    with z(_cols=len(classifiers)):
        for classifier in classifiers:
            plot_call_score_hist(run, classifier=classifier, _zplots_context=z)

    # Do PR plots for each classifier grouped together. If there are proteins of
    # interest, then each call will already result in multiple plots, but if there are
    # not, each call will only be one plot, so in that case group them on the same
    # to to make comparison between classifiers easier.
    zOpts = {} if run.prep.n_pros_of_interest > 0 else {"_cols": 2}
    with z(**zOpts):
        for classifier in classifiers:
            plot_peptide_observability_vs_precision(
                run, classifier=classifier, _zplots_context=z
            )
            plot_pr_for_run(run, _noise=0.01, classifier=classifier, _zplots_context=z)


# Sigproc related
# -----------------------


def _raw_peak_i_zoom(
    field_i,
    res,
    df,
    peak_i,
    channel=0,
    zoom=3.0,
    square_radius=7,
    x_pad=0,
    cspan=(0, 5_000),
    separate=False,
    show_circles=True,
):
    peak_i = int(peak_i)
    peak_records = df[df.peak_i == peak_i]
    field_i = int(peak_records.iloc[0].field_i)

    im = res.raw_chcy_ims(field_i)
    all_sig = res.signal_radmat()

    square = cspan[1] * imops.generate_square_mask(square_radius)

    sig_for_channel = all_sig[peak_i, channel, :]
    sig_top = np.median(sig_for_channel) + np.percentile(sig_for_channel, 99.9)

    height = (square_radius + 1) * 2 + 1
    one_width = height + x_pad
    all_width = one_width * res.n_cycles - x_pad
    im_all_cycles = np.zeros((height, all_width))

    f_plot_height = height * zoom
    f_plot_width = all_width * zoom

    z = ZPlots()
    if show_circles:
        for cycle_i in range(res.n_cycles):
            im_with_marker = np.copy(im[channel, cycle_i])
            cy_rec = peak_records[peak_records.cycle_i == cycle_i].iloc[0]
            loc = XY(cy_rec.raw_x, cy_rec.raw_y)

            imops.accum_inplace(im_with_marker, square, loc=loc, center=True)
            im_with_marker = imops.extract_with_mask(
                im_with_marker,
                imops.generate_square_mask(square_radius + 1, True),
                loc=loc,
                center=True,
            )
            imops.accum_inplace(
                im_all_cycles, im_with_marker, loc=XY(cycle_i * one_width, 0)
            )

            if separate:
                z.im(
                    im_with_marker,
                    _noaxes=True,
                    f_plot_height=int(f_plot_height),
                    f_plot_width=int(f_plot_height),
                    _notools=True,
                    f_match_aspect=True,
                    _cspan=cspan,
                )

    if not separate:
        z.im(
            im_all_cycles,
            _noaxes=True,
            f_plot_height=int(f_plot_height),
            f_plot_width=int(f_plot_width),
            _notools=True,
            f_match_aspect=True,
            _cspan=cspan,
        )


def wizard_raw_images(
    run,
    max_bright=15_000,
    show_circles=True,
    peak_i_square=True,
    square_radius=4,
    cycle_stride=1,
    horizontal_layout=False,
    result_block="sigproc_v1",
):
    """
    Wizard to explore raw images

    Audience:
        Trained technicians.

    Goal:
        Allow user to see:
            Raw images
    """

    from IPython.core.display import display, HTML  # Defer slow imports
    from ipywidgets import interact_manual  # Defer slow imports

    res = run[result_block]
    df = res.fields__n_peaks__peaks()

    def show_raw(peak_i, field_i, max_bright, show_circles):
        field_i = int(field_i) if field_i != "" else None
        if field_i is None:
            peak_i = int(peak_i)
            peak_records = df[df.peak_i == peak_i]
            field_i = int(peak_records.iloc[0].field_i)
        else:
            peak_i = None

        all_sig = res.signal_radmat()

        # mask_rects_for_field = res.raw_mask_rects_df()[field_i]
        # Temporarily removed. This is going to involve some groupby Super-Pandas-Kungfu(tm)
        # Here is my too-tired start...
        """
        import pandas as pd
        df = pd.DataFrame([
            (0, 0, 0, 100, 110, 120, 130),
            (0, 0, 1, 101, 111, 121, 131),
            (0, 0, 2, 102, 112, 122, 132),
            (0, 1, 0, 200, 210, 220, 230),
            (0, 1, 1, 201, 211, 221, 231),
            (0, 1, 2, 202, 212, 222, 232),
            (1, 0, 0, 1100, 1110, 1120, 1130),
            (1, 0, 1, 1101, 1111, 1121, 1131),
            (1, 0, 2, 1102, 1112, 1122, 1132),
            (1, 1, 0, 1200, 1210, 1220, 1230),
            (1, 1, 1, 1201, 1211, 1221, 1231),
        ], columns=["frame_i", "ch_i", "cy_i", "x", "y", "w", "h"])

        def rec(row):
            return row[["x", "y"]]

        df.set_index("frame_i").groupby(["frame_i"]).apply(rec)
        """
        mask_rects_for_field = None

        cspan = (0, max_bright)
        circle = cspan[1] * imops.generate_donut_mask(4, 3)
        square = cspan[1] * imops.generate_square_mask(square_radius)
        z = ZPlots()
        for input_ch in range(res.n_channels):
            display(HTML(f"<h3>Channel {input_ch}</h3>"))
            sig_for_channel = all_sig[:, input_ch, :]
            sig_top = np.median(sig_for_channel) + np.percentile(sig_for_channel, 99.9)

            if peak_i is not None:
                rad = sig_for_channel[peak_i]
                rad = rad.reshape(1, rad.shape[0])
                print(
                    "\n".join(
                        [
                            f"    cycle {cycle:2d}: {r:6.0f}"
                            for cycle, r in enumerate(rad[0])
                        ]
                    )
                )
                z.scat(x=range(len(rad[0])), y=rad[0])
                z.im(rad, _cspan=(0, sig_top), f_plot_height=50, _notools=True)

                # This is inefficient because the function we will call
                # does the same image load, but I'd prefer to not repeat
                # the code here and want to be able to call this fn
                # from notebooks:
                _raw_peak_i_zoom(
                    field_i,
                    res,
                    df,
                    peak_i,
                    input_ch,
                    zoom=3.0,
                    square_radius=square_radius,
                    x_pad=1,
                    cspan=cspan,
                    separate=False,
                    show_circles=show_circles,
                )

        # Note that raw_ims has ALL channels but the sigprocv2 might only
        # have operated on some of them
        raw_ims = res.raw_chcy_ims(field_i)

        n_input_channels = res.n_input_channels

        cycle_iz = list(range(0, res.n_cycles, cycle_stride))
        if res.n_cycles - 1 not in cycle_iz:
            cycle_iz += [res.n_cycles - 1]

        input_channel_iz = range(n_input_channels)

        row_iz = cycle_iz if not horizontal_layout else input_channel_iz
        col_iz = input_channel_iz if not horizontal_layout else cycle_iz

        with z(_cols=len(col_iz), _cspan=cspan):

            for row_i in row_iz:
                for col_i in col_iz:

                    cycle_i = row_i if not horizontal_layout else col_i
                    input_ch = col_i if not horizontal_layout else row_i

                    output_ch = res.params.input_channel_to_output_channel(input_ch)
                    im_with_marker = np.copy(raw_ims[input_ch, cycle_i])
                    # if (
                    #     mask_rects_for_field is not None
                    #     and mask_rects_for_field[input_ch] is not None
                    # ):
                    #     mask_rects = mask_rects_for_field[input_ch][cycle_i]
                    #     for rect in mask_rects:
                    #         imops.edge_fill(
                    #             im_with_marker,
                    #             loc=XY(rect[0], rect[1]),
                    #             dim=WH(rect[2], rect[3]),
                    #         )

                    if peak_i is not None:
                        cy_rec = peak_records[peak_records.cycle_i == cycle_i].iloc[0]
                        im_marker = square if peak_i_square else circle
                        imops.accum_inplace(
                            im_with_marker,
                            im_marker,
                            loc=XY(cy_rec.raw_x, cy_rec.raw_y),
                            center=True,
                        )
                    elif show_circles and output_ch is not None:
                        # Note that peaks are peaks in all channels - it's tools to have a peptide
                        # with multiple channel/labels - but it does not mean you'll see signal
                        # in a given channel.
                        peak_records = df[
                            (df.field_i == field_i) & (df.cycle_i == cycle_i)
                        ]
                        # In the case of a field with no peaks, n_peaks may be NaN, so check that we have
                        # some peaks before passing NaNs to imops.
                        if peak_records.n_peaks.iloc[0] > 0:
                            for i, peak in peak_records.iterrows():
                                imops.accum_inplace(
                                    im_with_marker,
                                    circle,
                                    loc=XY(peak.raw_x, peak.raw_y),
                                    center=True,
                                )

                    z.im(
                        im_with_marker,
                        f_title=f"CH{input_ch}  cycle {cycle_i}  field {field_i}",
                        _full=True,
                        _noaxes=True,
                        _cspan=(0, float(max_bright)),
                    )
        displays.fix_auto_scroll()

    interact_manual(
        show_raw,
        peak_i="1",
        field_i="",
        max_bright=max_bright,
        show_circles=show_circles,
    )


def wizard_scat_df(
    run,
    default_x="field_i",
    default_y="signal",
    channel_i=None,
    result_block="sigproc_v1",
):
    """
    Wizard to explore sigprocv2 data on any pivot.

    Audience:
        Trained technicians.

    Goal:
        Allow user to see:
            Any pivot version of the sigprocv2 data
    """
    from ipywidgets import interact  # Defer slow imports
    from bokeh.plotting import figure, ColumnDataSource, show  # Defer slow imports

    df = run[result_block].fields__n_peaks__peaks__radmat()
    if channel_i is not None:
        df = df[df.channel_i == channel_i].reset_index()
    x_name_wid = displays.dropdown(df, "X:", default_x)
    y_name_wid = displays.dropdown(df, "Y:", default_y)

    def scat(x_name, y_name, x_noise):
        n_peaks = df.shape[0]
        n_samples = 3000
        mask = data.subsample(np.arange(n_peaks), n_samples)
        _df = df.loc[mask].copy()
        _df[x_name] = _df[x_name] + np.random.uniform(-x_noise, +x_noise, size=len(_df))
        source = ColumnDataSource(_df)
        f = figure(
            tooltips=displays.tooltips(df),
            x_axis_label=x_name,
            y_axis_label=y_name,
            plot_width=800,
            plot_height=800,
        )
        f.scatter(x=x_name, y=y_name, fill_alpha=0.5, line_color=None, source=source)
        show(f)

    interact(scat, x_name=x_name_wid, y_name=y_name_wid, x_noise=0.1)


def wizard_xy_df(run, channel_i=None, result_block="sigproc_v1", **kwargs):
    """
    Wizard to explore sigprocv2 data as a function of the stage

    Audience:
        Trained technicians.

    Goal:
        Allow user to see:
            Any anomalies that are occuring as a result of the stage position
    """
    from ipywidgets import interact  # Defer slow imports
    from bokeh.models import ColorBar  # Defer slow imports
    from bokeh.plotting import figure, ColumnDataSource, show  # Defer slow imports
    from bokeh.transform import linear_cmap  # Defer slow imports
    from bokeh.palettes import Viridis256, Category20

    stage_df = (
        run.ims_import.metadata()
        .groupby("field_i")[["stage_x", "stage_y"]]
        .mean()
        .reset_index()
    )

    df = run[result_block].fields__n_peaks__peaks__radmat()
    df = df.drop(["stage_x", "stage_y"], axis=1)

    df = df.set_index("field_i").join(stage_df.set_index("field_i"))

    if "stage_x" not in df.columns:
        print("No stage information in sigprocv2 data.  Tif import without metadata?")
        return

    # If there are any fields that had no peaks found, many of the numeric fields that we
    # may want to plot will contain NaN and generate an exception below.  To allow the
    # viz to highlight the problem, fill these values (e.g. n_peaks, etc) with 0
    # If 0 turns out to be inappropriate for some columns, pass a df of values for cols.
    # See below where I have made color 0 bright red to highlight these.
    df = df.fillna(0)

    if channel_i is not None:
        df = df[df.channel_i == channel_i].reset_index()

    heat_name_wid = displays.dropdown(df, "", "n_peaks")

    def heat(heat_name):
        try:
            field_grp = df.groupby(["field_i"])
            means_df = field_grp[["stage_x", "stage_y", heat_name]].mean()
            min_ = means_df[heat_name].min()
            max_ = means_df[heat_name].max()
            if max_ == min_:
                # ZBS: I hit a problem where the eps caused an exception
                # Just chaning it to 1 for now
                max_ = min_ + 1  # np.finfo(float).eps
            val = (255 * (means_df[heat_name] - min_) / (max_ - min_)).astype(int)
            lut = np.array(Viridis256)
            colors = lut[val]

            source = ColumnDataSource(means_df)

            # TODO?: I wanted values set to 0 via df.fillna(0) above to be highlighted, and in general
            # you can't tell apart "the lowest" from other low values in these heatmaps.  So I made the first
            # color bright red - but that means that all items that fall into the lowest of the
            # 256 bins will get colored red.  Maybe this is not a good solution, but as I play
            # with the heatmap using this scheme, I find that it is drawing my attention to
            # some interesting things, so I'm leaving it for now.
            palette = list(Viridis256)
            palette[0] = "#FF0000"

            mapper = linear_cmap(
                field_name=heat_name, palette=palette, low=min_, high=max_
            )
            f = figure(
                match_aspect=True,
                tooltips=displays.tooltips(df),
                plot_width=800,
                plot_height=800,
            )
            f.rect(
                # Note these x/y values are where the rect is centered - are the stage?
                x="stage_x",
                y="stage_y",
                width=90,
                height=90,
                source=source,
                color=mapper,
            )
            color_bar = ColorBar(
                color_mapper=mapper["transform"], width=8, location=(0, 0)
            )
            f.add_layout(color_bar, "right")
            show(f)
        except Exception as e:
            debug(e)

    interact(heat, heat_name=heat_name_wid)


def wizard_df_filter(run, limit_columns=None):
    """
    Wizard to explore sigprocv2 data as a a large table

    Audience:
        Trained technicians.

    Goal:
        Allow user to see:
            Any anomalies that are occuring as a result of the stage position
    """
    import qgrid  # Defer slow imports

    if limit_columns is not None:
        df = run.sigproc_v1.all_df()[limit_columns]
    else:
        df = run.sigproc_v1.fields__n_peaks__peaks__radmat()

    return qgrid.show_grid(df, show_toolbar=True, precision=2, grid_options=dict())


def plot_channel_signal_histograms(
    run, limit_cycles=None, limit_field=None, div_noise=False, **kw
):
    # Used in sigproc_template
    _x_ticks = Munch(
        precision=0, use_scientific=True, power_limit_high=0, power_limit_low=0
    )
    if "_x_ticks" not in kw:
        kw["_x_ticks"] = _x_ticks

    limit_cycles = (
        range(run.sigproc_v1.n_cycles) if limit_cycles is None else limit_cycles
    )
    n_bins = 100

    field_label = "(all fields)" if limit_field is None else f"field {limit_field}"

    def get_signal():
        signal = (
            run.sigproc_v1.signal_radmat()
            if limit_field is None
            else run.sigproc_v1.signal_radmat_for_field(limit_field)
        )
        if div_noise:
            noise = (
                run.sigproc_v1.noise_radmat()
                if limit_field is None
                else run.sigproc_v1.noise_radmat_for_field(limit_field)
            )
            signal = utils.np_safe_divide(signal, noise, default=0)

        return signal

    def _hist_ch_cy(ch, cy):
        ch_signal = get_signal()[:, slice(ch, ch + 1, 1), slice(cy, cy + 1, 1)]
        non_nan = ch_signal[~np.isnan(ch_signal)]

        # If there is no signal then add a zero entry to satisfy logic below.
        if non_nan.shape[0] == 0:
            non_nan = np.array([[0]])

        p99 = np.percentile(non_nan, 99)
        _hist, _edges = np.histogram(non_nan, bins=n_bins)

        # consider returning _hist[1:].max() below because the 0-bin is often dominating
        # and the shape of the rest of the data is generally more interesting?
        return non_nan, p99, _hist.max()

    # Establish uniform axes by sampling everything in a first pass
    max_x = 0
    max_y = 0
    for cy in limit_cycles:
        for ch in range(run.sigproc_v1.n_channels):
            _, x, y = _hist_ch_cy(ch, cy)
            max_x = max(max_x, x)
            max_y = max(max_y, y)

    if kw.get("_range_only", 0):
        return max_x, max_y

    z = kw.get("_zplots_context", ZPlots())
    with z(
        _cols=None if "_cols" in kw else run.sigproc_v1.n_channels,
        f_plot_width=250,
        f_plot_height=250,
        f_x_range=kw.get("f_x_range", (0, max_x)),
        f_y_range=kw.get("f_y_range", (0, max_y * 1.1)),
    ):
        for cy in limit_cycles:
            for ch in range(run.sigproc_v1.n_channels):
                data, _, _ = _hist_ch_cy(ch, cy)
                z.hist(
                    data,
                    _bins=n_bins,
                    f_title=f"CH{ch} cycle {cy} {field_label}",
                    **kw,
                )

    return max_x, max_y


# In development
# ====================================================================================================


def text_sigproc_overview(run):
    # Number of fields, Number of peaks,

    ch_map = " ".join(
        [
            f"{in_ch}->{run.sigproc_v1.params.input_channel_to_output_channel(in_ch)}"
            for in_ch in range(run.sigproc_v1.params.n_input_channels)
        ]
    )

    print(
        f"Sigproc ran over:\n"
        f"  {run.sigproc_v1.n_fields} fields\n"
        f"  {run.sigproc_v1.params.n_input_channels} input channels\n"
        f"Sigproc wrote:\n"
        f"  {run.sigproc_v1.params.n_output_channels} output channels\n"
        f"  {len(run.sigproc_v1.peaks()):,} peaks were found\n"
        f"The channel mapping was:\n"
        f"  {ch_map}\n"
    )


def plot_sigproc_stats(run):
    # Hist quality, peaks per field, background, etc.
    # Maybe done as rows per field heatmap
    z = ZPlots()
    with z(_cols=4, f_plot_width=250, f_plot_height=280):
        fields_df = run.sigproc_v1.fields()
        z.hist(
            fields_df.quality,
            f_x_axis_label="quality",
            f_y_axis_label="n_frames",
            _bins=np.linspace(0, 400, 100),
        )
        by_quality = run.sigproc_v1.fields().sort_values(by="quality")

        def get(i):
            row = by_quality.iloc[i]
            im = run.sigproc_v1.raw_im(row.field_i, row.channel_i, row.cycle_i)
            return im, row

        best_im, best = get(-1)
        worst_im, worst = get(0)
        median_im, median = get(run.sigproc_v1.n_frames // 2)
        cspan = (0, np.percentile(median_im.flatten(), q=99, axis=0))
        z.im(
            best_im,
            _cspan=cspan,
            f_title=f"Best field={best.field_i} channel={best.channel_i} cycle={best.cycle_i}",
        )
        z.im(
            median_im,
            _cspan=cspan,
            f_title=f"Median field={median.field_i} channel={median.channel_i} cycle={median.cycle_i}",
        )
        z.im(
            worst_im,
            _cspan=cspan,
            f_title=f"Worst field={worst.field_i} channel={worst.channel_i} cycle={worst.cycle_i}",
        )


def plot_channel_signal_scatter(run, ch0=0, ch1=1, **kwargs):
    sample_size = kwargs.get("sample_size", 500)
    n_std_plot_range = kwargs.get("n_std_plot_range", 4)
    r = run.sigproc_v1.radmats()
    n_peaks = len(r.peak_i.unique())

    title = (
        f"ch{ch1} vs ch{ch0} signal, n={sample_size}, axis-range={n_std_plot_range}-STD"
    )
    md(f"## {title}")

    sample = np.random.choice(range(n_peaks), replace=False, size=sample_size)

    max_x = max_y = 0
    z = ZPlots()
    with z(_cols=4, f_plot_width=250, f_plot_height=280):
        for cy in range(run.sigproc_v1.n_cycles):
            x = r[(r.cycle_i == cy) & (r.channel_i == ch0)].signal.values
            y = r[(r.cycle_i == cy) & (r.channel_i == ch1)].signal.values
            x_sample = x[sample]
            y_sample = y[sample]
            if max_x == 0:
                max_x = np.mean(x_sample) + np.std(x_sample) * n_std_plot_range
                max_y = np.mean(y_sample) + np.std(y_sample) * n_std_plot_range
            z.scat(
                x=x_sample,
                y=y_sample,
                f_x_axis_label=f"signal, channel {ch0}",
                f_y_axis_label=f"signal, channel {ch1}",
                f_title=f"cycle {cy}",
                f_x_range=(0, max_x),
                f_y_range=(0, max_y),
            )


def text_lnfit_links(run):
    from plumbum import local

    names = LNFitResult.task_names(run)
    info(f"lnfit tasks in run: {names}")

    # We can use any name to get an lnfit result object
    # which deals with multiple lnfits per run for us.

    lnfit = run[names[0]]

    cwd = local.cwd
    for ch, html_files in enumerate(lnfit.html_files()):
        task_folder = html_files[0].split()[-2]
        md(f"### {task_folder}")
        m = ""
        for f in sorted(html_files):
            relative_path = f.relative_to(cwd)
            m += f"* [{f.name}]({relative_path})\n"
        md(m)


def plot_signal_for_lnfit_sequence(run, channel, sequence, lnfit_taskname=None):
    # Used in lnfit_template
    """
    Plot signal vs cycle for all peaks with a given lnfit sequence
    on a particular channel.

    sequence is e.g. '22221111000000'
    """

    names = LNFitResult.task_names(run)
    lnfit = run[names[0]]

    df_ln = lnfit.lnfit_bestseq_df(
        lnfit_taskname
    )  # contains lnfit bestseq per peak_i and channel;
    df = run.sigproc_v1.fields__n_peaks__peaks__radmat()
    df = pd.merge(df_ln, df, how="left", on=["peak_i", "channel_i"])

    filtered = df[(df.best_seq == sequence) & (df.channel_i == channel)].reset_index()
    peptide_count = int(len(filtered) / len(df.cycle_i.unique()))
    lnfit_name = lnfit_taskname or "All lnfits"
    md(
        f"### {peptide_count} peptides with lnfit sequence {sequence} on channel {channel}, {lnfit_name}"
    )

    if peptide_count > 0:
        # wizard_scat_df(filtered, default_x="cycle_i")
        # this now takes a run - todo?
        wizard_boxplot_df(
            filtered,
            "signal",
            "cycle_i",
            f_x_axis_label="Cycle",
            f_y_axis_label="Signal",
        )

    return filtered


def wizard_boxplot_df(
    df, value_col, group_col, f_x_axis_label=None, f_y_axis_label=None, f_title=None
):
    from bokeh.plotting import figure  # Defer slow imports
    from bokeh.io import show  # Defer slow imports

    #
    # Adapted from https://bokeh.pydata.org/en/latest/docs/gallery/boxplot.html
    #
    # This similar to the scat wizard, but with box & whisker.

    # find the quartiles and IQR for each category
    groups = df[[group_col, value_col]].groupby(group_col)
    q1 = groups.quantile(q=0.25)
    q2 = groups.quantile(q=0.5)
    q3 = groups.quantile(q=0.75)
    iqr = q3 - q1
    upper = q3 + 1.5 * iqr
    lower = q1 - 1.5 * iqr

    cats = sorted(list(groups.groups.keys()))

    # find the outliers for each category
    def outliers(group):
        cat = group.name
        return group[
            (group[value_col] > upper.loc[cat][value_col])
            | (group[value_col] < lower.loc[cat][value_col])
        ][value_col]

    out = groups.apply(outliers).dropna()

    # prepare outlier data for plotting, we need coordinates for every outlier.
    if not out.empty:
        outx = []
        outy = []
        for keys in out.index:
            outx.append(keys[0])
            outy.append(out.loc[keys[0]].loc[keys[1]])

    x_labels = range(14)
    count = groups.count()[value_col][0]
    p = figure(
        tools="",
        background_fill_color="#efefef",
        title=f_title,
        x_axis_label=f_x_axis_label,
        y_axis_label=f_y_axis_label,
        toolbar_location=None,
    )

    # if no outliers, shrink lengths of stems to be no longer than the minimums or maximums
    qmin = groups.quantile(q=0.00)
    qmax = groups.quantile(q=1.00)
    upper[value_col] = [
        min([x, y]) for (x, y) in zip(list(qmax.loc[:, value_col]), upper[value_col])
    ]
    lower[value_col] = [
        max([x, y]) for (x, y) in zip(list(qmin.loc[:, value_col]), lower[value_col])
    ]

    # stems
    p.segment(cats, upper[value_col], cats, q3[value_col], line_color="black")
    p.segment(cats, lower[value_col], cats, q1[value_col], line_color="black")

    # boxes
    p.vbar(
        cats,
        0.7,
        q2[value_col],
        q3[value_col],
        fill_color="#E08E79",
        line_color="black",
    )
    p.vbar(
        cats,
        0.7,
        q1[value_col],
        q2[value_col],
        fill_color="#3B8686",
        line_color="black",
    )

    # whiskers (almost-0 height rects simpler than segments)
    p.rect(cats, lower[value_col], 0.2, 0.01, line_color="black")
    p.rect(cats, upper[value_col], 0.2, 0.01, line_color="black")
    # outliers
    if not out.empty:
        p.circle(outx, outy, size=6, color="#F38630", fill_alpha=0.6)

    p.xgrid.grid_line_color = None
    p.ygrid.grid_line_color = "white"
    p.grid.grid_line_width = 2
    p.xaxis.major_label_text_font_size = "12pt"

    show(p)


def abund_abund_plot(
    needle_iz,
    needle_impact,
    labels,
    ref_df,
    exp_names,
    dfs,
    n_classes,
    score_thresh=0.0,
    percent_mode=True,
    title="",
    x_label="",
    y_label="",
    highlight_impacted=True,
    omit_needle=False,
):
    from bokeh.models import (
        HoverTool,
        PanTool,
        ResetTool,
        WheelZoomTool,
    )  # Defer slow imports
    from bokeh.plotting import figure, ColumnDataSource, show  # Defer slow imports

    def abun(df, n_classes):
        return (
            df[~df.rejection_mask]
            .groupby("cls_pred")
            .size()
            .reset_index(name="calls")
            .set_index("cls_pred")
            .reindex(np.arange(n_classes), fill_value=0)
            .calls.values
        )

    abun = [abun(df[df.cls_score >= score_thresh], n_classes) for df in [ref_df] + dfs]

    # TASK? We could probably alter the abun() function above to groupby cls_pred and peak_i,
    # but in several attempts to do this I couldn't get it right.  So here I'll factor out
    # the number of cycles so that we don't return multiples of n_cycles. TFB
    abun = np.stack(abun).T // ref_df.groupby("peak_i").size()[0]

    b = np.sum(abun, axis=0)
    abun_percent = abun / np.tile(b, (abun.shape[0], 1))

    # abund_frame has the calls for each peptide class as rows and each experiment as columns
    abund_frame = pd.DataFrame(
        abun_percent if percent_mode else abun, columns=["ref"] + exp_names
    )

    assert len(exp_names) == len(dfs)
    n_exp = len(exp_names)

    # would like to scale vertex size by relative contribution to calls
    # vertex size should be ~ log(#calls) & in the range ~ [2,6]
    # I want fraction .001 to be about 2 and to double in size every order of mag.
    log_abun = abun_percent.copy()
    log_abun[log_abun < 0.0005] = 0.0005
    log_abun = (np.log(log_abun) + 8.0) * 2.0

    abund_log_scaled_frame = pd.DataFrame(log_abun, columns=["ref"] + exp_names)

    line_xs = []
    line_ys = []
    line_colors = []
    vertex_xs = []
    vertex_ys = []
    vertex_colors = []
    vertex_sizes = []
    vertex_labels = []

    first_vals = abund_frame["ref"].values

    needle_color = ZPlots.feature
    needle_impact_color = ZPlots.compare1
    other_color = ZPlots.compare2

    for cls_i in range(n_classes):
        is_needle = cls_i in needle_iz
        is_impacted = needle_impact[cls_i] != 0

        if omit_needle and (is_needle or is_impacted):
            continue

        color = (
            needle_color
            if is_needle
            else (
                needle_impact_color
                if (is_impacted and highlight_impacted)
                else other_color
            )
        )

        for exp_i in range(n_exp - 1):
            vals_exp_i0 = abund_frame[exp_names[exp_i + 0]].values
            vals_exp_i1 = abund_frame[exp_names[exp_i + 1]].values
            line_xs += [(vals_exp_i0[cls_i], vals_exp_i1[cls_i])]
            line_ys += [(first_vals[cls_i], first_vals[cls_i])]
            line_colors += [color]

        for exp_i in range(n_exp):
            vals_exp_i0 = abund_frame[exp_names[exp_i]].values
            vertex_xs += [vals_exp_i0[cls_i]]
            vertex_ys += [first_vals[cls_i]]
            vertex_colors += [color]
            vertex_sizes += [abund_log_scaled_frame[exp_names[exp_i]].values[cls_i]]
            count_string = (
                f"({vals_exp_i0[cls_i] * 100:.1f} percent)"
                if percent_mode
                else f"({vals_exp_i0[cls_i]} calls)"
            )
            vertex_labels += [
                f"{exp_names[exp_i]} class {labels[cls_i]} {count_string} ni={needle_impact[cls_i] * 100:.1f}%"
            ]

    vertex_source = ColumnDataSource(
        dict(
            label=vertex_labels,
            vertex_xs=vertex_xs,
            vertex_ys=vertex_ys,
            vertex_colors=vertex_colors,
            vertex_sizes=vertex_sizes,
        )
    )

    if percent_mode:
        rng = (1e-6, 0.3)
    else:
        rng = (1, 1e6)

    hover_tool = HoverTool(names=["circles"], tooltips=[("", "@label")])
    tools = [hover_tool, WheelZoomTool(), PanTool(), ResetTool()]
    f = figure(
        x_range=rng,
        y_range=rng,
        x_axis_type="log",
        y_axis_type="log",
        tools=tools,
        title=title,
        x_axis_label=x_label,
        y_axis_label=y_label,
        plot_width=640,
        plot_height=640,
    )
    f.multi_line(line_xs, line_ys, line_color=line_colors, line_width=1)
    f.circle(
        name="circles",
        x="vertex_xs",
        y="vertex_ys",
        fill_color="vertex_colors",
        line_color="vertex_colors",
        size="vertex_sizes",
        source=vertex_source,
    )
    show(f)


# from plaster.run import data_tools
#
# np.set_printoptions(precision=3)
#

# TODO: This is broken due to multiple refactorings!


def abund_abund_runs(
    runs,
    percent_mode=True,
    title="",
    x_label="",
    y_label="",
    highlight_impacted=True,
    omit_needle=False,
):
    needle_class_iz = []
    needle_impact = []

    assert "classify_sigproc" in runs[0]
    peptides = runs[0].classify_sigproc.peptides
    n_classes = peptides.n_real_classes

    if "sim" in runs[0].plaster.plaster_source:
        # probably use protein_of_interest here instead.
        needle_ids = runs[0].plaster.plaster_source.simulation.parameters.prep.needles
        needle_class_iz = [peptides.id_component_to_class_i(id) for id in needle_ids]
        conf = assignment_tools.conf_mat(
            runs[0].classifier.test.true_y, runs[0].classifier.test.pred_y, n_classes
        )
        diag = np.diag(conf)
        rows = np.sum(conf, axis=1)
        self_impact = diag / rows
        # TASK: the following will break with multi-needle
        needle_impact = np.array(
            [
                conf[ci, ni] / np.sum(conf[ci, :])
                for ci in range(n_classes)
                for ni in needle_class_iz
            ]
        )
        # debug(needle_impact)

    labels = [
        peptides.pretty_print_peptide_class_str_by_i(i, terse=True)
        for i in range(n_classes)
    ]

    mode = "percent" if percent_mode else "count"
    default_title = f"Abundance v Abundance, classification {mode} by run"
    if omit_needle:
        default_title += ", background (non-impacted)"
    elif not highlight_impacted:
        default_title += ", background (includes impacted)"

    title = title or default_title
    y_label = y_label or f"Classification {mode}, Run 0"
    x_label = x_label or f"Classification {mode}, Run 1..N"

    ref_df = runs[0].sigproc_df
    exp_names = [(r.run_dir / "..").name for r in runs[1:]]
    dfs = [r.sigproc_df for r in runs[1:]]

    abund_abund_plot(
        needle_class_iz,
        needle_impact,
        labels,
        ref_df,
        exp_names,
        dfs,
        n_classes,
        score_thresh=0.01,
        percent_mode=percent_mode,
        title=title,
        x_label=x_label,
        y_label=y_label,
        highlight_impacted=highlight_impacted,
        omit_needle=omit_needle,
    )


def plot_sigproc_classify_overview(run, top_n_classes=10):
    """
    Overview stats/distribution of signal classification

    Audience:
        Average users

    Goal:
        Allow the user to see:
            if the decoy and real false rates have roughly equal distributions
            if high scores are a good predictor of correctness.

    Plan:
        This is probably not a long-term useful plot as the imposter map
        will probably communicate most of this information in a more useful way.
    """

    bag = run.classify_rf_call_bag()
    pred_counts = np.bincount(bag.pred_pep_iz, minlength=run.prep.n_peps)
    pred_counts_df = pd.DataFrame(
        dict(pep_i=np.arange(run.prep.n_peps), pred_counts=pred_counts)
    )

    pred_counts_df = (
        pred_counts_df.set_index("pep_i")
        .join(run.prep.pros__peps__pepstrs().set_index("pep_i"), how="left")
        .sort_index()
        .reset_index()
    )

    # overview
    md(f"## {bag.n_rows} spots classified")

    cols_to_show = ["pep_i", "pred_counts", "pro_id", "pro_is_decoy", "seqstr"]
    print(pred_counts_df.nlargest(10, "pred_counts")[cols_to_show])

    z = ZPlots()
    with z(_cols=2, fill_alpha=0.5, line_alpha=0.05):
        with z(f_title=f"Classification, fraction by index"):
            z.cols(pred_counts, color=z.compare1, legend_label="all classes")

        with z(f_x_range=[0, 1], f_title="Score distribution"):
            z.hist(bag.scores, color=z.compare2)


# PTM-related
# TODO: all of this must be reviewed/rewritten after recent refactors.
# ====================================================================


def _get_prs_for_ptm_positions(run, positions=None):
    assert "ptm" in run
    if not positions:
        if len(run.ptm.proteins_of_interest) == 1:
            ptm_aas = [label[0] for label in run.ptm.ptm_labels]
            poi_seq = next(
                p
                for p in run.prep.proteins
                if p and p.pro_id == run.ptm.proteins_of_interest[0]
            )
            positions = [i for i, aa in enumerate(poi_seq) if aa in ptm_aas]
            if not positions:
                print(
                    "No PTM sites for proteins_of_interest {run.ptm.proteins_of_interest[0]} with labels {ptm_aas}"
                )
                return
        else:
            print("No proteins_of_interest found for PTM run.")
            return
    assert type(positions) is list and type(positions[0]) is int
    positions = sorted(positions)

    df = run.ptm.giant_bag
    scores_col_name = "p4_scores"
    df[scores_col_name] = df.p1_scores * df.p2_scores

    prs_by_position = {}
    for pos in positions:
        true_col_name = f"p4_true_{pos}"
        pred_col_name = f"p4_pred_{pos}"

        # We can't do the PR on all rows, we only want rows corresponding to calls involving
        # global aa position 'pos'.  Those will be (a) all rows for which true_p4_{pos} is
        # non-zero - where p1_true is peptide containing 'pos', AND ADDITIONALLY (b) any rows
        # for which pred_p4_{pos} is non-zero.  SOME of these (b) will be for rows in which
        # the true_p4_{pos} is 0, meaning the p1 call incorrectly predicted the peptide
        # that contains the position of interest (true_p1 doesn't contain the position).
        # (Note that if you were to use ALL rows, you would count as "correct" calls
        # the many rows in which both true and pred will contain 0 because it isn't even
        # the peptide containing this pos, nor was it predicted to be)
        row_mask = np.array((df[true_col_name] > 0) | (df[pred_col_name] > 0))

        debug = False
        if debug:
            ####################################################
            # debug
            ptm_pep = [
                pep
                for pep in run.prep.peptides
                if pep and pep.span_contains(pos, poi_seq)
            ]
            if ptm_pep:
                ptm_pep = ptm_pep[0]
                print(
                    f"\n*** ptm at position {pos} is in peptide {ptm_pep.pro_id(), str(ptm_pep)} ***"
                )
            else:
                print("\n\n**********************************************")
                print(
                    f"*** WTF? no peptide found that contains ptm position {pos} (missing span info? ambiguous?)"
                )
                print("**********************************************\n\n")
                continue

            print(f"  ptm {pos} row_mask len {len(row_mask)} sum {row_mask.sum()}")

            # we expect true_p4_rows to have 1000*2^ptms count
            true_p4_mask = df[true_col_name] > 0
            true_p4_rows = np.argwhere(true_p4_mask).flatten()
            print(f"  we expect true_p4_rows to have 1000*2^ptms count:")
            print(
                f"  true_p4_rows = {true_p4_rows[0]}...{true_p4_rows[-1]} ; {true_p4_mask.sum()} entries"
            )

            # for this position, how many of the p1 calls were correct?
            p1_correct_mask = (
                df.p1_true_pep_iz[true_p4_mask] == df.p1_pred_pep_iz[true_p4_mask]
            )
            print(
                f"  correct p1 calls = {p1_correct_mask.sum()} of {len(p1_correct_mask)}"
            )

            print("call df.pr_curve() ->")
            # end debug
            ####################################################

        p, r, s, _ = df.pr_curve(
            true_col_name=true_col_name,
            pred_col_name=pred_col_name,
            scores_col_name=scores_col_name,
            subset_rows_mask=row_mask,
        )
        prs_by_position[pos] = (p, r, s)
    return prs_by_position


def plot_pr_for_ptms(run, positions=None, merge=True):
    prs_by_position = _get_prs_for_ptm_positions(run, positions)
    with z.Opts(_merge=merge):
        for pos, prs in prs_by_position.items():
            _plot_pr_curve(prs)


def _ptm_recall_at_precisions(p, r, precisions):
    recalls = []
    for threshold in precisions:
        p = np.nan_to_num(p, 0)
        arg = utils.np_arg_last_where(p > threshold)
        recalls += [r[arg] if arg is not None else 0]
    return recalls


def _ptm_recall_block(prs_by_position, precisions):
    # Input : dict global_position -> (p,r,s)
    # Output: ndarray 'block' of recalls at various precisions for each position
    #
    # The latter is e.g. output to CSV elsewhere

    n_thresh_precs = len(precisions)
    positions = sorted(prs_by_position.keys())
    assert type(positions[0]) is int
    n_ptm_positions = len(positions)

    block = np.full((n_ptm_positions, n_thresh_precs), np.nan)
    print("\n")
    for i, gpos in enumerate(positions):
        (p, r, s) = prs_by_position[gpos]
        recall_at_pos = _ptm_recall_at_precisions(p, r, precisions)
        block[i, :] = recall_at_pos[:]
    return block


def csv_ptm_precision_recall_report(runs, filename="ptm_recalls.csv", positions=[]):
    raise Exception(
        "DEPRECATED. Thi doesn't seem to be used and is confusingly in percent, not frac"
    )

    # Assemble a CSV
    # Display recall at these precision thresholds
    thresh_precs = np.array([0.99, 0.95, 0.90, 0.80, 0.70])

    row_header_0 = 0
    row_header_1 = 3
    row_header_2 = 4
    row_block_top = 5
    col_header_1 = 0
    col_header_2 = 2
    col_block_left = 3
    col_block_spacer = 1
    grid = np.empty((500, 300), dtype=object)

    recall_blocks = []
    for r in runs:
        prs_by_position = _get_prs_for_ptm_positions(r, positions)
        recall_blocks += [_ptm_recall_block(prs_by_position, thresh_precs)]

    n_ptm, n_precs = recall_blocks[0].shape
    ptm_positions = np.array(sorted(prs_by_position.keys()))
    grid[
        row_block_top : row_block_top + n_ptm, col_header_1 : col_header_1 + 1
    ] = ptm_positions[:, None]
    grid[row_header_1, col_header_1] = "PTM position"
    grid[row_header_2, col_header_2] = "Precision (%):"
    grid[
        row_header_0, col_header_1
    ] = "The recall (%) for each PTM position are given for each precision column (%)"

    n_runs = len(runs)
    for i, run in enumerate(runs):
        recall_block = recall_blocks[i]
        _n_ptm, _n_precs = recall_block.shape
        assert n_ptm == _n_ptm and n_precs == _n_precs
        col = col_block_left + (i * (n_precs + col_block_spacer))
        grid[row_header_1 : row_header_1 + 1, col : col + 1] = run.run_name
        grid[row_header_2 : row_header_2 + 1, col : col + n_precs] = 100 * thresh_precs
        recall_block = np.nan_to_num(recall_block, 0)
        grid[row_block_top : row_block_top + n_ptm, col : col + n_precs] = (
            recall_block * 100.0
        )

    # BEST
    best_col = 1 + col_block_left + (n_runs * (n_precs + col_block_spacer))
    n_thresh_precs = thresh_precs.shape[0]
    all_blocks = np.hstack(recall_blocks)
    assert all_blocks.shape[1] == n_runs * n_thresh_precs
    run_names = np.array([run.run_name for run in runs])
    for i in range(n_thresh_precs):
        stride = i + np.arange(n_runs) * n_thresh_precs
        best_i = np.argmax(all_blocks[:, stride], axis=1)
        best_v = np.max(all_blocks[:, stride], axis=1)
        col = best_col + 2 * i
        grid[row_header_1 : row_header_1 + 1, col : col + 1] = "BEST"
        grid[row_header_2 : row_header_2 + 1, col : col + 1] = 100 * thresh_precs[i]
        grid[row_block_top : row_block_top + n_ptm, col : col + 1] = run_names[
            best_i, None
        ]
        grid[row_block_top : row_block_top + n_ptm, col + 1 : col + 2] = (
            100 * best_v[:, None]
        )

    # EMIT grid to CSV
    print(utils.grid_to_csv(grid, "4.0f"), file=open(filename, "w"))
