"""
This is the Signal Processor that extracts data from images from the fluoro-sequencer microscope.

Nomenclature
    Field
        One position of the X/Y stage
    Channel
        One wavelength of measured light
    Cycle
        One chemical cycle (Pre, Mock or Edman)
    Anomaly
        An area of an image that has a problem (dust, etc)
    Raw image
        Unmodified images from the scope
    Regional
        When a parameter is varies spatially
    Balance image
        A raw image scaled to compensate for regional uneven illumination
        and for differences between channels.
    Aligned field stack
        The scope stage is not perfect and does not return to exactly the same position
        each cycle, a computational alignment correction finds the optimal X/Y translation.
    ROI
        A Region Of Interest
    Intersection ROI
        In an aligned field stack, the Intersection ROI is the set
        of pixels that are in every cycle.  Ie, typically smaller than the
        dimensions of the raw images.
    Composite image
        When one or more of the channels/cycles for a field are stacked
    Fiducial images
        An image that is intended only to enhance the alignment or
        peak finding algorithm. These images are temporary and discarded after use.
    Peak/Loc/Spot
        A Peak, LOC-action, or Spot found in the image that presumably
        is generated by a single molecule.
    Radmat (aka "Radiometry Matrix")
        A matrix such that each row is a peak and each column is a measurement of brightness
        for each channel/cycle.
        Sometimes stored in (n_peaks, n_channels, n_cycles)
        Sometimes stored flatten as (n_peaks, n_channels * n_cycles)
    Radrow
        A single row (cooresponding to a single peak) of a radmat.
    cy_ims
        A set of images through all cycles for one field/channel.
    chcy_ims
        A set of images for all channel/cycles for one field.
    flchcy_ims
        A set of images for all field/channel/cycles.


Calibration-Related Components
    Sigproc Calibration is a notebook activity until we can automated it well.
    It records a Calibration object that contains:
        * regional_illumination_balance
        * regional_bg_mean
        * regional_bg_std
        * regional_psf_zstack
        * zstack_depths

V2 flow:
    0. Load calibration
        Compare the subject-id, brightness settings in the tsv files
        with what was in the calibration.
    1. Import balanced images
        Re-orders images in to output channel order
        Regionally balances images given calib
            (subtract background and scale regionally by the balance map)
        Channel equalize
            (Scale so all channels are the same strength)
    2. Mask anomalies
        Write nan into anomalies
    3. Align cycles
        Finds translations per cycles to align with cycle 0
    4. Composite with alignment offsets
        Discards pixels that are not in every cycle.
    5. Find peaks
    6. Radiometry
    7. Remove empties


TASKS:
    * Tune the size of the kernels used (1.5)
        Also, the peak_find has a similar hard-coded value

    * A general "anomaly" report section would be useful
        Frames that were very bad
        Frames where the SNR is really bad
        General histograms of quality, anomalies, and SNR

    * Examine each cycle and fit best z-depth of the PSFs
      and use that for the radiomtry of that cycle

    * _compute_channel_weights needs to change over to
      calibration-time computation.

"""

from enum import IntEnum
import numpy as np
import cv2
import pandas as pd
from munch import Munch
from plaster.tools.image.imops import sub_pixel_center
from plaster.tools.utils import utils
from plaster.tools.zap import zap
from plaster.tools.image import imops
from plaster.tools.image.coord import XY, YX, WH, HW, ROI
from plaster.tools.schema import check
from plaster.tools.calibration.calibration import Calibration
from plaster.run.sigproc_v2.sigproc_v2_result import SigprocV2Result
from plaster.run.sigproc_v2.sigproc_v2_params import SigprocV2Params
from plaster.tools.log.log import debug, info


# Helpers
# -------------------------------------------------------------------------------


def _kernel():
    """
    Return a zero-centered AUC=1.0 2D Gaussian for peak finding
    """
    std = 1.5  # This needs to be tuned and may be instrument dependent
    mea = 17
    kern = imops.gauss2_rho_form(
        amp=1.0,
        std_x=std,
        std_y=std,
        pos_x=mea // 2,
        pos_y=mea // 2,
        rho=0.0,
        const=0.0,
        mea=mea,
    )
    return kern - np.mean(kern)


def _intersection_roi_from_aln_offsets(aln_offsets, raw_dim):
    """
    Compute the ROI that contains pixels from all frames
    given the aln_offsets (returned from align_chcy_ims)
    and the dim of the original images.
    """
    aln_offsets = np.array(aln_offsets)
    check.affirm(
        np.all(aln_offsets[0] == (0, 0)), "intersection roi must start with (0,0)"
    )

    # intersection_roi is the ROI in the coordinate space of
    # the [0] frame that has pixels from every cycle.
    clip_dim = (
        np.min(aln_offsets[:, 0] + raw_dim[0]) - np.max(aln_offsets[:, 0]),
        np.min(aln_offsets[:, 1] + raw_dim[1]) - np.max(aln_offsets[:, 1]),
    )

    b = max(0, -np.min(aln_offsets[:, 0]))
    t = min(raw_dim[0], b + clip_dim[0])
    l = max(0, -np.min(aln_offsets[:, 1]))
    r = min(raw_dim[1], l + clip_dim[1])
    return ROI(loc=YX(b, l), dim=HW(t - b, r - l))


def _regional_bg_fg_stats(im, mask_radius=2, divs=5, return_ims=False):
    """
    Using an approximate peak kernel, separate FG and BG regionally
    and return the statistics.

    Arguments:
        im: a single frame
        mask_radius:
            Radius in pixels of extra space added around FG candidates
        divs:
            Regional divisions (both horiz and vert)
        return_ims
            If True, also return the fg_im, bg_im
            fg_im will have np.nan in all background spaces
            bg_im will have np.nan in the foreground spaces

    Returns:
        array(divs, divs, 4) with the 4 being: (bg_mean, bg_std, fg_mean, fg_std)
        Optionally returns fg_im, bg_im
    """
    circle = imops.generate_circle_mask(mask_radius).astype(np.uint8)

    kern = _kernel()
    cim = imops.convolve(np.nan_to_num(im, nan=np.nanmedian(im)), kern)

    # cim can end up with artifacts around the nans to the nan_mask
    # is dilated and splated as zeros back over the im
    nan_mask = cv2.dilate(np.isnan(im).astype(np.uint8), circle, iterations=1)

    # The negative side of the convoluted image has no signal
    # so the std of the symetric distribution (reflecting the
    # negative side around zero) is a good estimator of noise.
    if (cim < 0).sum() == 0:
        # Handle the empty case to avoid warning
        thresh = 1e10
    else:
        thresh = np.nanstd(np.concatenate((cim[cim < 0], -cim[cim < 0])))
        thresh = np.nan_to_num(
            thresh, nan=1e10
        )  # For nan thresh just make them very large
    cim = np.nan_to_num(cim)
    fg_mask = np.where(cim > thresh, 1, 0)

    fg_im = np.where(fg_mask & ~nan_mask, im, np.nan)

    fg_mask = cv2.dilate(fg_mask.astype(np.uint8), circle, iterations=1)
    bg_im = np.where(fg_mask | nan_mask, np.nan, im)

    def nanstats(dat):
        if np.all(np.isnan(dat)):
            return np.nan, np.nan
        return np.nanmean(dat), np.nanstd(dat)

    reg_bg_means, reg_bg_stds = imops.region_map(bg_im, nanstats, divs=divs)
    reg_fg_means, reg_fg_stds = imops.region_map(fg_im, nanstats, divs=divs)
    stats = np.stack((reg_bg_means, reg_bg_stds, reg_fg_means, reg_fg_stds), axis=2)
    if return_ims:
        return stats, fg_im, bg_im
    else:
        return stats


def _regional_balance_chcy_ims(chcy_ims, calib):
    """
    Balance and subtract background on each channel according to calibration data.

    Returns:
       balanced_chcy_ims: The regionally balanced chcy_ims
    """
    n_channels, n_cycles = chcy_ims.shape[0:2]
    balanced_chcy_ims = np.zeros_like(chcy_ims)
    dim = chcy_ims.shape[-2:]
    for ch in range(n_channels):
        regional_bg_mean = np.array(calib[f"regional_bg_mean.instrument_channel[{ch}]"])
        regional_balance = np.array(
            calib[f"regional_illumination_balance.instrument_channel[{ch}]"]
        )

        cy_ims = chcy_ims[ch]
        balance_im = imops.interp(regional_balance, dim)
        bg_im = imops.interp(regional_bg_mean, dim)

        if np.any(np.isnan(cy_ims)):
            raise ValueError(f"regional_balance_chcy_ims chcy_ims contains nan")
        if np.any(np.isnan(bg_im)):
            raise ValueError(f"regional_balance_chcy_ims bg_im contains nan")

        balanced_chcy_ims[ch] = (cy_ims - bg_im) * balance_im

    return balanced_chcy_ims


def circle_locs(im, locs, inner_radius=3, outer_radius=4, fill_mode="nan"):
    """
    Returns a copy of im with circles placed around the locs.

    Arguments
        im: The background image
        locs: Nx2 matrix of peak locations
        circle_radius: Radius of circle to draw
        fill_mode:
            "nan": Use im and overlay with circles of NaNs
            "index": zero for all background and the loc index otherwise
                     (This causes the loss of the 0-th peak)
        style_mode:
            "donut" Draw a 1 pixel donut
            "solid": Draw a filled circle

    This can then be visualized like:
        circle_im = circle_locs(im, locs, fill_mode="nan")
        z.im(circle_im, _nan_color="red")
    """
    mea = (outer_radius + 1) * 2 + 1
    hat = imops.generate_circle_mask(inner_radius, mea)

    brim = imops.generate_circle_mask(outer_radius, mea)
    brim = brim & ~hat

    if fill_mode == "nan":
        circle_im = np.zeros_like(im)
        for loc in locs:
            imops.set_with_mask_in_place(circle_im, brim, 1, loc=loc, center=True)
        return np.where(circle_im == 1, np.nan, im)

    if fill_mode == "index":
        circle_im = np.zeros_like(im)
        for loc_i, loc in enumerate(locs):
            imops.set_with_mask_in_place(circle_im, brim, loc_i, loc=loc, center=True)
        return circle_im


def _peak_find(im):
    """
    Peak find on a single image.

    In some cases this im might be a mean of multiple channels
    in other cases it might stand-alone on a single channel.

    Returns:
        locs: ndarray (n_peaks_found, 2) where the 2 is in (y,x) order
    """
    from skimage.feature import peak_local_max  # Defer slow import

    kern = _kernel()
    cim = imops.convolve(np.nan_to_num(im, nan=float(np.nanmedian(im))), kern)

    # The background is well-described by the the histogram centered
    # around zero thanks to the fact that im and kern are expected
    # to be roughly zero-centered. Therefore we estimate the threshold
    # by using the samples less than zero cim[cim<0] and taking the 99th percentile
    thresh = np.percentile(-cim[cim < 0], 99)
    cim[cim < thresh] = 0
    return peak_local_max(cim, min_distance=2, threshold_abs=thresh)


# PSF
# -------------------------------------------------------------------------------


class PSFEstimateMaskFields(IntEnum):
    """Mask fields returned as the second return of psf_estimate"""

    considered = 0
    skipped_near_edges = 1
    skipped_too_crowded = 2
    skipped_has_nan = 3
    skipped_empty = 4
    skipped_too_dark = 5
    skipped_too_oval = 6
    accepted = 7


def _psf_estimate(im, locs, mea, keep_dist=8, threshold_abs=None, return_reasons=True):
    """
    Given a single im, typically a regional sub-image, extract candidates
    for PSF averaging.

    Any one image may not produce enough (or any) candidate spots and it
    is therefore expected that this function is called over a large number
    of fields to get sufficient samples.

    Arguments:
        im: Expected to be a single field, channel, cycle. (expects background
            is subtracted.)
        locs: array (n, 2) in coordinates of im. Expected to be well-separated
        mea: The peak_measure (must be odd)
        threshold_abs: The average pixel brightness to accept the peak
        keep_dist: Pixels distance to determine crowding

    Returns:
        psf: ndarray (mea, mea) image
        reason_counts: An array of masks of why peaks were accepted/rejected
            See PSFEstimateMaskFields for the columns
    """
    from scipy.spatial.distance import cdist  # Defer slow import

    # Sanity check that background is removed
    assert np.nanmedian(im) < 5.0

    n_locs = len(locs)
    dist = cdist(locs, locs, metric="euclidean")
    dist[dist == 0.0] = np.nan

    if not np.all(np.isnan(dist)):
        closest_dist = np.nanmin(dist, axis=1)
    else:
        closest_dist = np.zeros(n_locs)

    # Aligned peaks will accumulate into this psf matrix
    dim = (mea, mea)
    psf = np.zeros(dim)

    n_reason_mask_fields = len(PSFEstimateMaskFields)
    reason_masks = np.zeros((n_locs, n_reason_mask_fields))

    for i, (loc, closest_neighbor_dist) in enumerate(zip(locs, closest_dist)):
        reason_masks[i, PSFEstimateMaskFields.considered] = 1
        peak_im = imops.crop(im, off=YX(loc), dim=HW(dim), center=True)

        if peak_im.shape != dim:
            # Skip near edges
            reason_masks[i, PSFEstimateMaskFields.skipped_near_edges] = 1
            continue

        if closest_neighbor_dist < keep_dist:
            reason_masks[i, PSFEstimateMaskFields.skipped_too_crowded] = 1
            continue

        if np.any(np.isnan(peak_im)):
            reason_masks[i, PSFEstimateMaskFields.skipped_has_nan] = 1
            continue

        # Sub-pixel align the peak to the center
        assert not np.any(np.isnan(peak_im))
        centered_peak_im = sub_pixel_center(peak_im)
        centered_peak_im = np.clip(centered_peak_im, a_min=0.0, a_max=None)
        peak_max = np.max(centered_peak_im)
        if peak_max == 0.0:
            reason_masks[i, PSFEstimateMaskFields.skipped_empty] = 1
            continue

        if threshold_abs is not None and peak_max < threshold_abs:
            # Reject spots that are not active
            reason_masks[i, PSFEstimateMaskFields.skipped_too_dark] = 1
            continue

        r = imops.distribution_aspect_ratio(centered_peak_im)
        if r > 2.0:
            reason_masks[i, PSFEstimateMaskFields.skipped_too_oval] = 1
            continue

        psf += centered_peak_im / np.sum(centered_peak_im)
        reason_masks[i, PSFEstimateMaskFields.accepted] = 1

    n_accepted = np.sum(reason_masks[:, PSFEstimateMaskFields.accepted])
    if n_accepted > 0:
        psf /= np.sum(psf)
        assert np.min(psf) >= 0.0

    if return_reasons:
        return psf, reason_masks
    return psf


def _psf_normalize(psfs):
    if psfs.ndim == 4:
        # This is a (div, div, mea, mea) psf estimate
        denom = np.sum(psfs, axis=(-2, -1))
        psfs = utils.np_safe_divide(psfs, denom[:, :, None, None])
    elif psfs.ndim == 5:
        # This is a (z, div, div, mea, mea) psf estimate
        denom = np.sum(psfs, axis=(-2, -1))
        psfs = utils.np_safe_divide(psfs, denom[:, :, :, None, None])
    return psfs


# Calibration
# -------------------------------------------------------------------------------


def _calibrate_bg_and_psf_im(im, divs=5, keep_dist=8, peak_mea=11, locs=None):
    """
    Run background & PSF calibration for one image.

    These are typically combined from many fields and for each channel
    to get a complete calibration.

    This returns the accepted locs so that a z-stack can be estimated
    by using the most in-focus frame for the locations

    Arguments:
        im: One image
        divs: Spatial divisions
        keep_dist: Pixel distancer under which is considered a collision
        peak_mea: n pixel width and height to hold the peak image
        locs: If None it will use the peak finder; otherwise these
              locs are being passed in and are expected to coorespond
              to the peak locs found in a previous step.

    Returns:
        locs (location of accepted peaks)
        regional_bg_mean
        regional_bg_std
        regional_psf_zstack
    """
    check.array_t(im, ndim=2)
    stats = _regional_bg_fg_stats(im, divs=divs)
    reg_bg_mean = stats[:, :, 0]
    reg_bg_std = stats[:, :, 1]
    check.array_t(reg_bg_mean, shape=(divs, divs))
    check.array_t(reg_bg_std, shape=(divs, divs))

    bg_im = imops.interp(reg_bg_mean, im.shape[-2:])
    im = im - bg_im

    if locs is None:
        locs = _peak_find(im)

    n_locs = locs.shape[0]
    accepted = np.zeros((n_locs,))

    # In each region gather a PSF estimate and a list of
    # locations that were accepted. These locs can be
    # re-used when analyzing other z slices
    reg_psfs = np.zeros((divs, divs, peak_mea, peak_mea))
    for win_im, y, x, coord in imops.region_enumerate(im, divs):
        mea = win_im.shape[0]
        assert win_im.shape[1] == mea

        local_locs = locs - coord
        local_locs_mask = np.all((local_locs > 0) & (local_locs < mea), axis=1)
        local_locs = local_locs[local_locs_mask]
        n_local_locs = local_locs.shape[0]

        psfs, reasons = _psf_estimate(
            win_im, local_locs, peak_mea, keep_dist=keep_dist, return_reasons=True
        )
        reg_psfs[y, x] = psfs

        # for reason in (
        #     PSFEstimateMaskFields.accepted,
        #     # PSFEstimateMaskFields.skipped_near_edges,
        #     # PSFEstimateMaskFields.skipped_too_crowded,
        #     # PSFEstimateMaskFields.skipped_has_nan,
        #     # PSFEstimateMaskFields.skipped_empty,
        #     # PSFEstimateMaskFields.skipped_too_dark,
        #     # PSFEstimateMaskFields.skipped_too_oval,
        # ):
        #     n_local_rejected = (reasons[:, reason] > 0).sum()
        #     print(f"y,x={y},{x} {str(reason)}:, {n_local_rejected}")

        # Go backwards from local to global space.
        local_accepted_iz = np.argwhere(
            reasons[:, PSFEstimateMaskFields.accepted] == 1
        ).flatten()
        local_loc_i_to_global_loc_i = np.arange(n_locs)[local_locs_mask]
        assert local_loc_i_to_global_loc_i.shape == (n_local_locs,)

        global_accepted_iz = local_loc_i_to_global_loc_i[local_accepted_iz]
        accepted[global_accepted_iz] = 1

    return locs[accepted > 0], reg_bg_mean, reg_bg_std, reg_psfs


def _calibrate(flchcy_ims, divs=5, progress=None, overload_psf=None):
    """
    Accumulate calibration data using a set of fields.

    Arguments:
        flchcy_ims: frame, channel, cycles ims to be analyzed
            These are typically only a small subset of high quality fields.
            NOTE: "Cycles" here are considered to be z-stack slices, NOT chem-cycles.
        divs: The regional sub-divisions.
    """

    n_fields, n_channels, n_cycles = flchcy_ims.shape[0:3]
    n_z_slices = n_cycles  # This is just an alias to remind me that cycle=z-slice here.

    peak_mea = 11
    peak_dim = (peak_mea, peak_mea)

    if overload_psf is not None:
        # This is used for testing
        peak_dim = overload_psf.shape

    calib = Calibration()

    for ch_i in range(n_channels):
        z_and_region_to_psf = np.zeros((n_z_slices, divs, divs, *peak_dim))

        # BACKGROUND
        # Masks out the foreground and uses remaining pixels to estimate
        # regional background mean and std.
        # --------------------------------------------------------------

        flcy_calibs = [
            _calibrate_bg_and_psf_im(flchcy_ims[fl_i, ch_i, cy_i])
            for fl_i in range(n_fields)
            for cy_i in range(n_cycles)
        ]

        calib.add(
            {
                f"regional_bg_mean.instrument_channel[{ch_i}]": np.mean(
                    [
                        np.array(
                            flcy_calibs[f"regional_bg_mean.instrument_channel[{ch_i}]"]
                        )
                        for c in flcy_calibs
                    ]
                )
            }
        )

        # reg_psfs = np.sum([
        #     np.array(c[f"regional_psf_zstack.instrument_channel[{ch_i}]"])
        #     for c in flcy_calibs
        # ], axis=(2, 3))
        #
        # denominator = np.sum(z_and_region_to_psf, axis=(2, 3))[:, :, None, None]
        # calib.add({
        #     f"regional_psf_zstack.instrument_channel[{ch_i}]": reg_psfs /
        # })
        #
        # z_and_region_to_psf = utils.np_safe_divide(z_and_region_to_psf, denominator)
        #
        # calib.add({
        #     f"regional_bg_std.instrument_channel[{ch_i}]": np.mean([
        #         np.array(c[f"regional_bg_std.instrument_channel[{ch_i}]"])
        #         for c in flcy_calibs
        #     ])
        # })

        # if overload_psf is not None:
        #     # This is used for testing
        #     z_and_region_to_psf = np.broadcast_to(
        #         overload_psf, (n_z_slices, divs, divs, *peak_dim)
        #     ).tolist()
        #
        # else:
        #     # PSF
        #     # Accumulate the PSF regionally over every field
        #     # Then divide each PSF though by it's own mass so that the
        #     # AUC under each PSF is 1.
        #     # --------------------------------------------------------------
        #     [
        #         _calibrate_bg_im(flchcy_ims[fl_i, ch_i, cy_i], regional_bg_mean, regional_bg_std)
        #         for fl_i in range(n_fields)
        #         for cy_i in range(n_cycles)
        #     ]
        #
        #     for fl_i in range(n_fields):
        #
        #         for cy_i in range(n_cycles):
        #             # Remember: cy_i is a pseudo-cycle: it is really a z-slice
        #             # with z_depths[cy_i] holding the actual depth
        #
        #             regional_bg_mean = np.array(
        #                 calib[f"regional_bg_mean.instrument_channel[{ch_i}]"]
        #             )
        #             _calibrate_psf_im(flchcy_ims[fl_i, ch_i, cy_i], regional_bg_mean)
        #
        #             # ACCUMULATE each field, will normalize at the end
        #             z_and_region_to_psf[cy_i] += reg_psfs

        # # NORMALIZE all psfs
        # denominator = np.sum(z_and_region_to_psf, axis=(3, 4))[:, :, :, None, None]
        # z_and_region_to_psf = utils.np_safe_divide(z_and_region_to_psf, denominator)
        #
        # calib.add(
        #     {
        #         f"regional_psf_zstack.instrument_channel[{ch_i}]": z_and_region_to_psf.tolist()
        #     }
        # )

        # FOREGROUND
        # Runs the standard sigproc_field analysis (without balancing)
        # to get the regional radmats for regional histogram balancing.
        # This requires that the PSF already be estimated so that the
        # radiometry can run.
        # --------------------------------------------------------------

        # Spoof the sigproc_v2 worker into bypassing illumination balance by giving it all zeros
        calib.add(
            {
                f"regional_illumination_balance.instrument_channel[{ch_i}]": np.ones(
                    (divs, divs)
                ).tolist()
            }
        )

        sigproc_params = SigprocV2Params(
            calibration=calib,
            instrument_subject_id=None,
            radiometry_channels=dict(ch=ch_i),
        )
        fl_radmats = []
        fl_locs = []
        for fl_i in range(n_fields):
            if progress is not None:
                progress(fl_i, n_fields)
            chcy_ims = flchcy_ims[fl_i, ch_i : (ch_i + 1), :]
            (chcy_ims, locs, radmat, aln_offsets, aln_scores,) = sigproc_field(
                chcy_ims, sigproc_params
            )
            fl_radmats += [radmat]
            fl_locs += [locs]
        fl_radmat = np.concatenate(fl_radmats)
        fl_loc = np.concatenate(fl_locs)

        # BALANCE
        sig = np.nan_to_num(fl_radmat[:, ch_i, :, 0].flatten())
        noi = fl_radmat[:, ch_i, :, 1].flatten()
        snr = np.nan_to_num(sig / noi)

        locs = np.tile(fl_loc, (1, n_cycles)).reshape((-1, 2))

        snr_mask = snr > 10
        sig = sig[snr_mask]
        locs = locs[snr_mask]

        top = np.max((locs[:, 0], locs[:, 1]))
        y = utils.ispace(0, top, divs + 1)
        x = utils.ispace(0, top, divs + 1)

        def regional_locs_mask(yi, xi):
            """Create a mask for locs inside of a region"""
            mask = (y[yi] <= locs[:, 0]) & (locs[:, 0] < y[yi + 1])
            mask &= (x[xi] <= locs[:, 1]) & (locs[:, 1] < x[xi + 1])
            return mask

        medians = np.zeros((divs, divs))
        for yi in range(len(y) - 1):
            for xi in range(len(x) - 1):
                loc_mask = regional_locs_mask(yi, xi)
                bright_mask = sig > 2.0
                _sig = sig[loc_mask & bright_mask]
                medians[yi, xi] = np.median(_sig)

        center = np.max(medians)
        balance = np.zeros((divs, divs))
        for yi in range(len(y) - 1):
            for xi in range(len(x) - 1):
                loc_mask = regional_locs_mask(yi, xi)
                bright_mask = sig > 2.0
                _sig = sig[loc_mask & bright_mask]

        for yi in range(len(y) - 1):
            for xi in range(len(x) - 1):
                loc_mask = regional_locs_mask(yi, xi)
                bright_mask = sig > 2.0
                _sig = sig[loc_mask & bright_mask]
                median = np.median(_sig)
                balance[yi, xi] = center / median
                _sig *= balance[yi, xi]

        calib.add(
            {
                f"regional_illumination_balance.instrument_channel[{ch_i}]": balance.tolist()
            }
        )

    return calib


def calibrate(ims_import_res, n_best_fields=6, divs=5, metadata=None, progress=None):
    if metadata is None:
        metadata = {}
    calib = Calibration({f"metadata.instrument": metadata})

    qdf = ims_import_res.qualities()
    quality = qdf.sort_values(["field_i", "channel_i", "cycle_i"])[
        "quality"
    ].values.reshape(
        (ims_import_res.n_fields, ims_import_res.n_channels, ims_import_res.n_cycles)
    )
    best_field_iz = np.argsort(np.sum(quality, axis=(1, 2)))[::-1][
        0:n_best_fields
    ].tolist()

    n_cycles = ims_import_res.n_cycles
    zstack_depths = [
        0
    ] * n_cycles  # TASK: This will need to come from ims_import_res metadata
    calib.add({f"zstack_depths.instrument": zstack_depths})

    _calibrate(
        ims_import_res.ims[best_field_iz, :, :], calib, divs=divs, progress=progress
    )

    return calib


# Step 1: Order channels, regional balance and channel equalize
# -------------------------------------------------------------------------------


def _compute_channel_weights(sigproc_params):
    """
    Import channels and order them into the output order
    (evert input channel is not necessarily used).
    """
    # TODO: This needs to be converted to calibration time and a new channel-equalization variable is needed
    calib = sigproc_params.calibration
    n_out_channels = sigproc_params.n_output_channels
    channel_weights = np.ones((n_out_channels))
    for out_ch in range(n_out_channels):
        in_ch = sigproc_params.output_channel_to_input_channel(out_ch)
        regional_fg_thresh = np.array(
            calib[f"regional_bg_mean.instrument_channel[{in_ch}]"]
        )
        channel_weights[out_ch] = np.sum(regional_fg_thresh)
    channel_weights = np.max(channel_weights) / channel_weights
    return channel_weights


def _import_balanced_images(chcy_ims, sigproc_params):
    """
    Import channels and order them into the output order
    (evert input channel is not necessarily used).

    Regionally balance and channel equalize.

    Note:
        Because the background is subctracted, the returned
        images may contain negative values.
    """
    calib = sigproc_params.calibration
    n_out_channels = sigproc_params.n_output_channels
    dst_chcy_ims = np.zeros((n_out_channels, *chcy_ims.shape[-3:]))
    for out_ch in range(n_out_channels):
        in_ch = sigproc_params.output_channel_to_input_channel(out_ch)
        dst_chcy_ims[out_ch] = chcy_ims[in_ch]
    chcy_ims = dst_chcy_ims

    chcy_ims = _regional_balance_chcy_ims(chcy_ims, calib)

    channel_weights = _compute_channel_weights(sigproc_params)
    chcy_ims = utils.np_fn_along(np.multiply, chcy_ims, channel_weights, axis=0)

    return chcy_ims


# Step 2: Mask anomalies
# -------------------------------------------------------------------------------


def _mask_anomalies_im(im, den_threshold=300):
    """
    Operates on pre-balanced images.
    The den_threshold of 300 was found empirically on Val data

    Sets anomalies to nan
    """
    import skimage.transform  # Defer slow imports
    import cv2

    check.array_t(im, is_square=True)

    # SLICE into square using numpy-foo by reshaping the image
    # into a four-dimensional array can then by np.mean on the inner dimensions.
    sub_mea = 4  # Size of the sub-sample region
    im_mea, _ = im.shape

    squares = im.reshape(im_mea // sub_mea, sub_mea, im_mea // sub_mea, sub_mea)
    # At this point, im is now 4-dimensional like: (256, 2, 256, 2)
    # But we want the small_dims next to each other for simplicity so swap the inner axes
    squares = squares.swapaxes(1, 2)
    # Now squares is (256, 256, 2, 2.)

    # squares is like: 256, 256, 2, 2. So we need the mean of the last two axes
    squares = np.mean(squares, axis=(2, 3))

    bad_mask = (squares > den_threshold).astype(float)

    # EXPAND the bad areas by erosion and dilate.
    # Erosion gets rid of the single-pixel hits and dilation expands the bad areas
    kernel = np.ones((3, 3), np.uint8)
    mask = cv2.erode(bad_mask, kernel, iterations=1)
    mask = cv2.dilate(mask, kernel, iterations=3)

    scale = im.shape[0] // mask.shape[0]

    full_size_mask = skimage.transform.rescale(
        mask, scale=scale, multichannel=False, mode="constant", anti_aliasing=False
    ).astype(bool)

    # FIND rect contours of bad areas
    contours, hierarchy = cv2.findContours(
        full_size_mask.astype("uint8"), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE
    )
    bad_rects = [cv2.boundingRect(cnt) for cnt in contours]
    im = im.copy()
    for rect in bad_rects:
        imops.fill(im, loc=XY(rect[0], rect[1]), dim=WH(rect[2], rect[3]), val=np.nan)

    return im


# Step 3: Find alignment offsets
# -------------------------------------------------------------------------------


def _align(cy_ims):
    """
    Align a stack of cy_ims by generating simplified fiducial for each cycle
    (assumes camera does not move between channels)

    Returns:
        aln_offsets: list of YX tuples
        max_score: list of max_score
    """

    kern = _kernel()

    fiducial_ims = []
    for im in cy_ims:
        med = float(np.nanmedian(im))
        im = np.nan_to_num(im, nan=med)
        fiducial_ims += [imops.convolve(im, kern)]
    fiducial_ims = np.array(fiducial_ims) - np.median(fiducial_ims)
    noise_floor = -np.min(fiducial_ims)
    fiducial_ims = np.where(fiducial_ims < noise_floor, 0, 1).astype(np.uint8)

    kern = imops.generate_circle_mask(3).astype(np.uint8)

    fiducial_cy_ims = np.array(
        [cv2.dilate(im, kern, iterations=1) for im in fiducial_ims]
    ).astype(float)

    aln_offsets, aln_scores = imops.align(fiducial_cy_ims)
    return aln_offsets, aln_scores


# Step 4: Composite with alignment offsets
# -------------------------------------------------------------------------------


def _composite_with_alignment_offsets_chcy_ims(chcy_ims, aln_offsets):
    """
    Given the alignment_offsets, create a new image stack that
    has the dimensions of the intersection ROI (ie the overlapping
    region that contains pixels from all cycles)

    Note:
        The returned image is likely smaller than the chcy_ims shape.
    """
    n_channels, n_cycles = chcy_ims.shape[0:2]
    check.array_t(aln_offsets, shape=(n_cycles, 2))
    assert n_cycles == aln_offsets.shape[0]

    raw_dim = chcy_ims.shape[-2:]
    roi = _intersection_roi_from_aln_offsets(aln_offsets, raw_dim)
    roi_dim = (roi[0].stop - roi[0].start, roi[1].stop - roi[1].start)

    aligned_chcy_ims = np.zeros((n_channels, n_cycles, *roi_dim))
    for cy, offset in zip(range(n_cycles), aln_offsets):
        shifted_im = imops.shift(chcy_ims[:, cy], -offset)
        aligned_chcy_ims[:, cy, 0 : roi_dim[0], 0 : roi_dim[1]] = shifted_im[
            :, roi[0], roi[1]
        ]

    return aligned_chcy_ims


# Step 6: Radiometry measures the signal and noise of each peak
# -------------------------------------------------------------------------------
def _peak_radiometry(
    peak_im, psf_kernel, center_weighted_mask, allow_non_unity_psf_kernel=False
):
    """
    Compute radiometry on a single peak.

    Arguments:
        peak_im: a small regional image of a peak roughly centered.
                 This expected to be from a regionally balance and channel equalized
                 source image with the regional background already subtracted

        psf_kernel: The kernel appropriate for the region (from calibration)

    Returns:
        signal: The area under the kernel (always >= 0)
        noise: The standard deviation of the residuals (always >= 0)
    """
    check.array_t(peak_im, ndim=2, is_square=True)
    check.array_t(psf_kernel, ndim=2, is_square=True)
    check.array_t(center_weighted_mask, ndim=2, is_square=True)
    assert peak_im.shape == psf_kernel.shape
    assert psf_kernel.shape == center_weighted_mask.shape

    if not allow_non_unity_psf_kernel:
        assert 1.0 - np.sum(psf_kernel) < 1e-6

    # Weight the peak_im by the centering_kernel to eliminate
    # noise from neighbors during COM calculations

    # SHIFT peak_im to center with sub-pixel alignment
    # Note, we scale peak_im by the centering_kernel so that
    # the COM will not be polluted by neighbors

    com_before = imops.com((center_weighted_mask * peak_im) ** 2)
    center_pixel = np.array(peak_im.shape) / 2
    peak_im = center_weighted_mask * imops.sub_pixel_shift(
        peak_im, center_pixel - com_before
    )

    # WEIGH the data with the psf_kernel and then normalize
    # by the psf_kernel_sum_squared to estimate signal
    psf_kernel_sum_squared = np.sum(psf_kernel ** 2)
    signal = 0.0
    if psf_kernel_sum_squared > 0.0:
        signal = np.sum(psf_kernel * peak_im) / psf_kernel_sum_squared

    # COMPUTE the noise by examining the residuals
    residuals = peak_im - signal * psf_kernel
    var_residuals = np.var(residuals)
    noise = 0.0
    if psf_kernel_sum_squared > 0.0:
        noise = np.sqrt(var_residuals / psf_kernel_sum_squared)

    if noise <= 0.0 or signal <= 0.0:
        signal = np.nan
        noise = np.nan

    return signal, noise


def _radiometry(chcy_ims, locs, ch_z_reg_psfs, cycle_to_z_index):
    """
    Use the PSFs to compute the Area-Under-Curve of the data in chcy_ims
    for each peak location of locs.

    Arguments:
        chcy_ims: (n_output_channels, n_cycles, width, height)
        locs: (n_peaks, 2). The second dimension is in (y, x) order
        ch_z_reg_psfs: (n_output_channels, n_z_slices, divs, divs, psf_mea, psf_mea)
        cycle_to_z_index: (n_cycles).
            This is the best z-slice of the ch_z_reg_psfs to use for
            each cycle determined by a focal fit.
    """
    check.array_t(chcy_ims, ndim=4)
    check.array_t(locs, ndim=2, shape=(None, 2))
    check.array_t(
        ch_z_reg_psfs, shape=(chcy_ims.shape[0], None, None, None, None, None)
    )
    check.array_t(cycle_to_z_index, shape=(chcy_ims.shape[1],))

    n_locs = len(locs)
    n_channels, n_cycles = chcy_ims.shape[0:2]
    psf_divs = ch_z_reg_psfs.shape[2]
    assert psf_divs == ch_z_reg_psfs.shape[3]
    psf_dim = ch_z_reg_psfs.shape[-2:]
    psf_mea = psf_dim[0]
    assert psf_mea == psf_dim[1]

    radmat = np.full((n_locs, n_channels, n_cycles, 2), np.nan)  # 2 is (sig, noi)

    center_weighted_mask = imops.generate_center_weighted_tanh(psf_mea, radius=2.0)

    for ch_i in range(n_channels):
        for cy_i in range(n_cycles):
            reg_psfs = ch_z_reg_psfs[ch_i, cycle_to_z_index[cy_i]]

            im = chcy_ims[ch_i, cy_i]

            for loc_i, loc in enumerate(locs):
                peak_im = imops.crop(im, off=YX(loc), dim=HW(psf_dim), center=True)
                if peak_im.shape != psf_dim:
                    # Skip near edges
                    continue

                if np.any(np.isnan(peak_im)):
                    # Skip nan collisions
                    continue

                # There is a small issue here -- when the regional PSFs
                # are computed they divide up the image over the full width
                # but the locs here are actually referring to the aligned
                # space which is typically a little smaller. This might
                # cause problems if alignment is very poor but is probably
                # too small of an effect to worry about in typical operations.
                psf_kernel = reg_psfs[
                    int(psf_divs * loc[0] / im.shape[0]),
                    int(psf_divs * loc[1] / im.shape[1]),
                ]

                signal, noise = _peak_radiometry(
                    peak_im, psf_kernel, center_weighted_mask=center_weighted_mask
                )
                radmat[loc_i, ch_i, cy_i, :] = (signal, noise)

    return radmat


# Entrypoint
# -------------------------------------------------------------------------------


def sigproc_field(chcy_ims, sigproc_params, snr_thresh=None):
    """
    Analyze one field and return values (do not save)

    Arguments:
        chcy_ims: In input order (from ims_import_result)
        sigproc_params: The SigprocParams
        snr_thresh: if non-None keeps only locs with S/R > snr_thresh
            This is useful for debugging.
    """

    calib = Calibration(sigproc_params.calibration)

    # Step 1: Load the images in output channel order, balance, equalize
    chcy_ims = _import_balanced_images(chcy_ims, sigproc_params)
    # At this point, chcy_ims has its background subtracted and it is
    # regionally balanced and channel equalized. It may contain negative
    # values
    #
    # NOTE: at this point, chcy_ims are in OUTPUT CHANNEL order!
    n_out_channels, n_cycles = chcy_ims.shape[0:2]
    assert n_out_channels == sigproc_params.n_output_channels

    # Step 2: Remove anomalies
    for ch_i, cy_ims in enumerate(chcy_ims):
        chcy_ims[ch_i] = imops.stack_map(cy_ims, _mask_anomalies_im)

    # Step 3: Find alignment offsets
    aln_offsets, aln_scores = _align(np.mean(chcy_ims, axis=0))

    # Step 4: Composite with alignment
    chcy_ims = _composite_with_alignment_offsets_chcy_ims(chcy_ims, aln_offsets)
    # chcy_ims is now only the intersection region so it may be smaller than the original

    # Step 5: Peak find on combined channels
    # The goal of previous channel equalization and regional balancing is that
    # all pixels are now on an equal footing so we can now use
    # a single values for fg_thresh and bg_thresh.
    ch_mean_of_cy0_im = np.mean(chcy_ims[:, 0, :, :], axis=0)
    locs = _peak_find(ch_mean_of_cy0_im)

    # Step 6: Radiometry over each channel, cycle
    # TASK: Eventually this will examine each cycle and decide
    # which z-depth of the PSFs is best fit to that cycle.
    # The result will be a per-cycle index into the chcy_regional_psfs
    # Until then the index is hard-coded to the zero-th index of regional_psf_zstack
    ch_z_reg_psfs = np.stack(
        [
            np.array(
                calib[
                    f"regional_psf_zstack.instrument_channel[{sigproc_params.output_channel_to_input_channel(out_ch_i)}]"
                ]
            )
            for out_ch_i in range(n_out_channels)
        ],
        axis=0,
    )
    assert ch_z_reg_psfs.shape[0] == n_out_channels
    cycle_to_z_index = np.zeros((n_cycles,)).astype(int)
    radmat = _radiometry(chcy_ims, locs, ch_z_reg_psfs, cycle_to_z_index)

    # Step 7: Remove empties
    # Keep any loc that has a signal > 20 times the minimum bg std in any channel
    # The 20 was found somewhat empirically and may need to be adjusted
    keep_mask = np.zeros((radmat.shape[0],)) > 0
    for out_ch_i in range(n_out_channels):
        in_ch_i = sigproc_params.output_channel_to_input_channel(out_ch_i)
        bg_std = np.min(calib[f"regional_bg_std.instrument_channel[{in_ch_i}]"])
        keep_mask = keep_mask | np.any(radmat[:, out_ch_i, :, 0] > 20 * bg_std, axis=1)

    if snr_thresh is not None:
        snr = radmat[:, :, :, 0] / radmat[:, :, :, 1]
        keep_mask = keep_mask & np.any(np.nan_to_num(snr) > snr_thresh, axis=(1, 2))

    return chcy_ims, locs[keep_mask], radmat[keep_mask], aln_offsets, aln_scores


def _do_sigproc_field(ims_import_result, sigproc_params, field_i, sigproc_result):
    """
    Analyze AND SAVE one field.
    """
    chcy_ims = ims_import_result.field_chcy_ims(field_i)

    chcy_ims, locs, radmat, aln_offsets, aln_scores = sigproc_field(
        chcy_ims, sigproc_params
    )

    n_channels, n_cycles, roi_h, roi_w = chcy_ims.shape

    peak_df = pd.DataFrame(
        [(0, field_i, peak_i, loc[0], loc[1]) for peak_i, loc in enumerate(locs)],
        columns=list(SigprocV2Result.peak_df_schema.keys()),
    )

    field_df = pd.DataFrame(
        [
            (
                field_i,
                channel_i,
                cycle_i,
                aln_offsets[cycle_i, 0],
                aln_offsets[cycle_i, 1],
                aln_scores[cycle_i],
            )
            for channel_i in range(n_channels)
            for cycle_i in range(n_cycles)
        ],
        columns=list(SigprocV2Result.field_df_schema.keys()),
    )

    assert len(radmat) == len(peak_df)

    sigproc_result.save_field(
        field_i,
        peak_df=peak_df,
        field_df=field_df,
        radmat=radmat,
        _aln_chcy_ims=chcy_ims,
    )


def sigproc(sigproc_params, ims_import_result, progress=None):
    """
    Analyze all fields
    """
    calib = Calibration(sigproc_params.calibration)
    assert not calib.is_empty()

    channel_weights = _compute_channel_weights(sigproc_params)

    sigproc_result = SigprocV2Result(
        params=sigproc_params,
        n_input_channels=ims_import_result.n_channels,
        n_channels=sigproc_params.n_output_channels,
        n_cycles=ims_import_result.n_cycles,
        channel_weights=channel_weights,
    )

    n_fields = ims_import_result.n_fields
    n_fields_limit = sigproc_params.n_fields_limit
    if n_fields_limit is not None and n_fields_limit < n_fields:
        n_fields = n_fields_limit

    zap.work_orders(
        [
            Munch(
                fn=_do_sigproc_field,
                ims_import_result=ims_import_result,
                sigproc_params=sigproc_params,
                field_i=field_i,
                sigproc_result=sigproc_result,
            )
            for field_i in range(n_fields)
        ],
        _trap_exceptions=False,
        _progress=progress,
    )

    return sigproc_result
