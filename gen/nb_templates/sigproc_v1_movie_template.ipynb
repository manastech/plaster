{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @IMPORT-MERGE\n",
    "from plaster.run.run import RunResult\n",
    "from plaster.run.plots import plots\n",
    "from plaster.tools.ipynb_helpers import displays\n",
    "from munch import Munch\n",
    "from plumbum import local\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plaster.tools.zplots import zplots\n",
    "z = zplots.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "from plumbum import local\n",
    "print(local.cwd)\n",
    "\n",
    "src = local.path( \"../../../jobs_folder/jhm_20200124_tfawashout_methanol_4min_220frames/sigproc_0_4_minute\"  )\n",
    "run = RunResult( src )\n",
    "displays.title( src.name )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Visualization (\"movie\" format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displays.subtitle(\"Overview\")\n",
    "plots.text_sigproc_overview(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displays.subtitle( \"Quality\")\n",
    "plots.plot_sigproc_stats(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of signal and signal/noise (SNR) for first and last cycles\n",
    "#\n",
    "titles = ['Peak signal distribution by field, first/last cycles',\n",
    "          'Peak SNR distribution by field, first/last cycles' ]\n",
    "all_titles = [ \"Peak signal distribution, all fields combined, first/last cycle\",\n",
    "               \"Peak SNR distribution, all fields combined, first/last cycle\"]\n",
    "div_noise = [ False, True ]\n",
    "\n",
    "for title,all_title,is_snr in zip( titles, all_titles, div_noise ):\n",
    "    # Do a first pass to get range so all plots can be same scale\n",
    "    max_x = 0\n",
    "    max_y = 0\n",
    "    for field in range(run.sigproc.n_fields):\n",
    "        _mx,_my = plots.plot_channel_signal_histograms( run, limit_field=field, limit_cycles=[0,run.sigproc.n_cycles-1], div_noise=is_snr, _range_only=True )\n",
    "        max_x = max( _mx, max_x )\n",
    "        max_y = max( _my, max_y )\n",
    "\n",
    "    # And then plot.  If this is single-channel data, which is tools in photobleaching experiments, \n",
    "    # lay this out horizontally.\n",
    "    displays.subtitle(title)\n",
    "    if run.sigproc.n_channels==1:\n",
    "        with z(_cols=run.sigproc.n_fields):\n",
    "            for field in range(run.sigproc.n_fields):\n",
    "                plots.plot_channel_signal_histograms( run, limit_field=field, limit_cycles=[0], div_noise=is_snr, f_x_range=(0,max_x), f_y_range=(0,max_y*1.1), _cols=run.sigproc.n_fields, _zplot_context=z )\n",
    "            for field in range(run.sigproc.n_fields):\n",
    "                plots.plot_channel_signal_histograms( run, limit_field=field, limit_cycles=[run.sigproc.n_cycles-1], div_noise=is_snr, f_x_range=(0,max_x), f_y_range=(0,max_y*1.1), _cols=run.sigproc.n_fields, _zplot_context=z )\n",
    "    else:\n",
    "        for field in range(run.sigproc.n_fields):\n",
    "            plots.plot_channel_signal_histograms( run, limit_field=field, limit_cycles=[0,run.sigproc.n_cycles-1], div_noise=is_snr, f_x_range=(0,max_x), f_y_range=(0,max_y*1.1) )\n",
    "    \n",
    "#     displays.subtitle(all_title)\n",
    "#     _,_ = plots.plot_channel_signal_histograms( run, limit_cycles=[0,run.sigproc.n_cycles-1], div_noise=is_snr, f_x_range=(0,max_x)  )\n",
    "\n",
    "\n",
    "# Uncomment to see all frames\n",
    "#displays.subtitle(\"Peaks intensity distribution histograms for every cycle, all fields combined\")\n",
    "#plot_channel_signal_histograms( run )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# photobleaching curve - what is the average signal at each cycle?\n",
    "df = run.sigproc.fields__n_peaks__peaks__radmat()\n",
    "displays.subtitle( \"Average signal is expected to decay by cycle due to bleaching\")\n",
    "avg_sig = df.groupby('cycle_i')['signal'].mean()\n",
    "med_sig = df.groupby('cycle_i')['signal'].median()\n",
    "max_y = max( np.max(avg_sig), np.max(med_sig ) )\n",
    "with z( _cols=2, f_y_range=[0,max_y*1.1] ):\n",
    "    z.scat(x=range(avg_sig.shape[0]),y=avg_sig,f_title='average signal by cycle, all fields combined',f_y_axis_label='average signal',f_x_axis_label='cycle')\n",
    "    z.scat(x=range(med_sig.shape[0]),y=med_sig,f_title='median signal by cycle, all fields combined',f_y_axis_label='median signal',f_x_axis_label='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displays.subtitle( \"Average signal, signal delta, and signal-delta as percentage, by field\")\n",
    "\n",
    "fields = sorted(df.field_i.unique())\n",
    "avg_sig = df.groupby(['field_i','cycle_i'])['signal'].mean()\n",
    "\n",
    "def good_field(f):\n",
    "    # This is not the case when for some field there is no signal\n",
    "    return type(avg_sig[f]) == pd.core.series.Series\n",
    "\n",
    "# compute signal delta\n",
    "zeros = np.zeros(run.sigproc.n_cycles)\n",
    "avg_sig_diff = np.array([ np.diff(avg_sig[f]) if good_field(f) else zeros for f in fields ])\n",
    "avg_sig_diff_pct = np.array([ avg_sig_diff[f] / avg_sig[f][1:] * 100 if good_field(f) else zeros for f in fields ])\n",
    "\n",
    "# compute the plot ranges to keep them all on same scale\n",
    "avg_sig_y = ( avg_sig.min() * .9, avg_sig.max() * 1.1)\n",
    "m = max( abs(avg_sig_diff.min()), abs(avg_sig_diff.max()) ) * 1.1\n",
    "avg_diff_y = ( -m, m )\n",
    "m = max( abs(avg_sig_diff_pct.min()), abs(avg_sig_diff_pct.max()) ) * 1.1\n",
    "avg_diff_pct_y = ( -m, m )\n",
    "\n",
    "# plot\n",
    "with z( _cols=3 ):\n",
    "    for f in fields:\n",
    "        if good_field(f):\n",
    "            z.scat( x=range(run.sigproc.n_cycles), y=avg_sig[f], f_title=f'average signal by cycle, field {f}',f_y_axis_label='average signal',f_x_axis_label='cycle',f_y_range=avg_sig_y )\n",
    "            z.scat( x=range(run.sigproc.n_cycles-1), y=avg_sig_diff[f], f_title=f'average signal delta at cycle, field {f}',f_y_axis_label='signal delta',f_x_axis_label='cycle',f_y_range=avg_diff_y )\n",
    "            z.scat( x=range(run.sigproc.n_cycles-1), y=avg_sig_diff_pct[f], f_title=f'average signal delta percentage at cycle, field {f}',f_y_axis_label='signal delta percentage',f_x_axis_label='cycle',f_y_range=avg_diff_pct_y )\n",
    "        else:\n",
    "            print( f\"(No data for field {f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jag/Jim exploratory functionality for photobleaching analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 1. Early brightness value\n",
    "#\n",
    "def get_signal_stats_for_cycles( df, cycle_start, n_cycles=1, channel=0, fields=None ):\n",
    "    '''\n",
    "        df          : the sigproc_df from a run\n",
    "        cycle_start : (int) starting cycle to collect stats for\n",
    "        n_cycles    : (int) how many cycles to collect status for\n",
    "        channel     : (int) which channel to include\n",
    "        fields      : None, int, or list of ints, which field(s) to include\n",
    "        \n",
    "        Returns:\n",
    "            a tuple of brightness stats: (mean, median, stddev)\n",
    "    '''\n",
    "    s = df[df['cycle_i'].between(cycle_start,cycle_start+n_cycles-1,inclusive=True)]\n",
    "    s = s[s.channel_i == channel]\n",
    "    fs = s.field_i.unique()\n",
    "    if fields is not None:\n",
    "        if not isinstance(fields,list):\n",
    "            fields=[fields]\n",
    "        s = s[s.field_i.isin(fields)]\n",
    "           \n",
    "    mean = s.signal.mean()\n",
    "    median = s.signal.median()\n",
    "    std = s.signal.std()\n",
    "    \n",
    "    snr = s.signal / s.noise\n",
    "    snr_mean = snr.mean()\n",
    "    snr_median = snr.median()\n",
    "    snr_std  = snr.std()\n",
    "        \n",
    "    return (mean,median,std,snr_mean,snr_median,snr_std)\n",
    "    \n",
    "#\n",
    "# Compute stats for brightness values starting at a given cycle, across n_cycles, for a given channel and field(s)\n",
    "#\n",
    "cycle_start = 0\n",
    "n_cycles    = 1\n",
    "channel     = 0\n",
    "fields      = None # None means use all fields.  Otherwise give a number or list of numbers, e.g. [0,1,2]\n",
    "    \n",
    "mean,median,stddev,snr_mean,snr_median,snr_std = get_signal_stats_for_cycles( run.sigproc.fields__n_peaks__peaks__radmat(), cycle_start=cycle_start, n_cycles=n_cycles, channel=channel, fields=fields )\n",
    "print( f\"mean {mean:g}, median {median:g}, stddev {stddev:g}, snr_mean={snr_mean:g}, snr_median{snr_median:g} snr_std {snr_std:g}\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peak lifetime analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displays.subtitle( \"Peak lifetime (intensity-threshold-based), by field\")\n",
    "\n",
    "# What is a reasonable threshold for \"dye is ON\" to pick automatically?\n",
    "# If we do some per-field analysis and pick some threshold based on the median, mean, etc\n",
    "# then this is somewhat circular with respect to talking about half-lives, thresholds, etc.\n",
    "# If we believe that in general we are running enough cycles such that fluorophores should be\n",
    "# mostly all bleached by the end, we could look at the average signal for last frame(s)\n",
    "# and set our threshold above this.  \n",
    "#\n",
    "# Really we need to know something about the dye - mean brightness + stddev to set this \n",
    "# threshold with confidence.\n",
    "# compute signal delta\n",
    "\n",
    "# Get the signal stats for computing threshold from each field, channel 0, last cycle\n",
    "channel = 0\n",
    "cycle_start = run.sigproc.n_cycles - 1\n",
    "n_cycles = 1\n",
    "radmat = run.sigproc.fields__n_peaks__peaks__radmat()\n",
    "fields = sorted(radmat.field_i.unique())\n",
    "n_std = 1 # how many standard-deviations above last-frame mean signal counts as \"On\"\n",
    "\n",
    "field_df = run.sigproc.fields()\n",
    "\n",
    "# Or a user may specify a \"hardcoded\" threshold to use here:\n",
    "# (The n_std above mean per field will be used otherwise)\n",
    "user_threshold = None\n",
    "\n",
    "for f in fields:\n",
    "    r = radmat[ radmat.field_i == f ].copy()\n",
    "    mean0,median0,stddev0,_,_,_ = get_signal_stats_for_cycles( r, cycle_start=0, n_cycles=1, channel=channel )\n",
    "    mean,median,stddev,_,_,_ = get_signal_stats_for_cycles( r, cycle_start=cycle_start, n_cycles=n_cycles, channel=channel )\n",
    "\n",
    "    threshold = mean + stddev * n_std  # mean + n_std\n",
    "    threshold = median\n",
    "    if user_threshold is not None:\n",
    "        threshold = user_threshold\n",
    "    \n",
    "    r['peak_is_on'] = r.signal > threshold\n",
    "    g = r.groupby(['peak_i'])\n",
    "    peak_lifetime = g.apply(lambda grp: run.sigproc.n_cycles if np.all(grp.peak_is_on) else np.where(grp.peak_is_on==False)[0][0] )\n",
    "    peaks_on_at_cycle =  [ (c <= peak_lifetime.values).sum() for c in range(run.sigproc.n_cycles+1) ]\n",
    "    \n",
    "    exposure = field_df[field_df.field_i==f].exposure_time[0]\n",
    "    \n",
    "    with z(_cols=4):\n",
    "        z.scat( x=range(run.sigproc.n_cycles+1), y=peaks_on_at_cycle, f_title=f\"Field {f} peaks on at cycle, threshold={int(threshold)}\", f_x_axis_label=f\"n_cycles ({int(exposure)}ms exposure)\", f_y_axis_label=\"count\")\n",
    "        z.hist( peak_lifetime, _bins=20, f_title=f\"Field {f} peak lifetime, threshold={int(threshold)}\", f_x_axis_label=f\"n_cycles ({int(exposure)}ms exposure)\", f_y_axis_label=\"count\")\n",
    "        \n",
    "\n",
    "        signals = radmat[(radmat.field_i==f) & (radmat.cycle_i==0)].signal\n",
    "        ymax = np.max(signals) \n",
    "        with z(_merge=True, f_title=f'Field {f} peaks, cycle 0', f_x_axis_label='peak number', f_y_axis_label='signal', f_y_range=[0,ymax]  ):\n",
    "            z.scat( x=range(len(signals)), y=signals ) \n",
    "            z.line( x=range(len(signals)), y=[threshold]*len(signals), color='red', line_width=2 ) \n",
    "\n",
    "        signals = radmat[(radmat.field_i==f) & (radmat.cycle_i==run.sigproc.n_cycles-1)].signal\n",
    "        with z(_merge=True, f_title=f'Field {f} peaks, cycle {run.sigproc.n_cycles-1}', f_x_axis_label='peak number', f_y_axis_label='signal', f_y_range=[0,ymax] ):\n",
    "            z.scat( x=range(len(signals)), y=signals)  \n",
    "            z.line( x=range(len(signals)), y=[threshold]*len(signals), color='red', line_width=2 ) \n",
    "            \n",
    "    print ( f'field {f} cycle   0:  mean {int(mean0)}  median {int(median0)} std {int(stddev0)}')\n",
    "    print ( f'field {f} cycle {cycle_start}:  mean {int(mean)}  median {int(median)} std {int(stddev)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displays.subtitle( \"Peak lifetime (SNR-threshold-based), by field\")\n",
    "\n",
    "# What if we pick a threshold for SNR instead of just signal?\n",
    "\n",
    "# Get the signal stats for computing threshold from each field, channel 0, last cycle\n",
    "channel = 0\n",
    "cycle_start = run.sigproc.n_cycles - 1\n",
    "n_cycles = 1\n",
    "radmat = run.sigproc.fields__n_peaks__peaks__radmat()\n",
    "fields = sorted(radmat.field_i.unique())\n",
    "n_std = 0\n",
    "\n",
    "field_df = run.sigproc.fields()\n",
    "\n",
    "# Or a user may specify a \"hardcoded\" threshold to use here:\n",
    "# (The n_std above mean per field will be used otherwise)\n",
    "user_snr_threshold = None\n",
    "\n",
    "for f in fields:\n",
    "    r = radmat[ radmat.field_i == f ].copy()\n",
    "    _,_,_,mean0,median0,stddev0 = get_signal_stats_for_cycles( r, cycle_start=0, n_cycles=1, channel=channel )\n",
    "    _,_,_,mean,median,stddev = get_signal_stats_for_cycles( r, cycle_start=cycle_start, n_cycles=n_cycles, channel=channel )\n",
    "\n",
    "    threshold = mean + stddev * n_std  # mean + n_std\n",
    "    threshold = median\n",
    "    if user_threshold is not None:\n",
    "        threshold = user_threshold\n",
    "    \n",
    "    r['peak_is_on'] = (r.signal/r.noise) > threshold\n",
    "    g = r.groupby(['peak_i'])\n",
    "    peak_lifetime = g.apply(lambda grp: run.sigproc.n_cycles if np.all(grp.peak_is_on) else np.where(grp.peak_is_on==False)[0][0] )\n",
    "    \n",
    "    exposure = field_df[field_df.field_i==f].exposure_time[0]\n",
    "    \n",
    "    with z(_cols=3):\n",
    "        z.hist( peak_lifetime, _bins=20, f_title=f\"Field {f} peak lifetime, threshold={threshold:.2f}\", f_x_axis_label=f\"n_cycles ({int(exposure)}ms exposure)\", f_y_axis_label=\"count\")\n",
    "\n",
    "        r = radmat[(radmat.field_i==f) & (radmat.cycle_i==0)]\n",
    "        signals = r.signal / r.noise\n",
    "        ymax = np.max(signals) \n",
    "        with z(_merge=True, f_title=f'Field {f} peaks, cycle 0', f_x_axis_label='peak number', f_y_axis_label='signal/noise', f_y_range=[0,ymax]  ):\n",
    "            z.scat( x=range(len(signals)), y=signals ) \n",
    "            z.line( x=range(len(signals)), y=[threshold]*len(signals), color='red', line_width=2 ) \n",
    "\n",
    "        r = radmat[(radmat.field_i==f) & (radmat.cycle_i==run.sigproc.n_cycles-1)]\n",
    "        signals = r.signal / r.noise\n",
    "        with z(_merge=True, f_title=f'Field {f} peaks, cycle {run.sigproc.n_cycles-1}', f_x_axis_label='peak number', f_y_axis_label='signal/noise', f_y_range=[0,ymax] ):\n",
    "            z.scat( x=range(len(signals)), y=signals)  \n",
    "            z.line( x=range(len(signals)), y=[threshold]*len(signals), color='red', line_width=2 ) \n",
    "            \n",
    "    print ( f'field {f} cycle   0: SNR mean {mean0:.2f}  median {median0:.2f} std {stddev0:.2f}')\n",
    "    print ( f'field {f} cycle {cycle_start}: SNR mean {mean:.2f}  median {median:.2f} std {stddev:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @REMOVE-FROM-TEMPLATE\n",
    "# e.g. sanity check the number of peaks whose lifetime is 0 because they're under the threshold\n",
    "# in the first cycle...\n",
    "field = 0\n",
    "cycle = 0\n",
    "signals = radmat[(radmat.field_i==field)&(radmat.cycle_i==cycle)]\n",
    "len(signals[signals.signal<=4027])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Half life analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 2. Half life\n",
    "#\n",
    "# First some function's we'll call.  Scroll down for user-edited code.\n",
    "#\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def average_signal_all_cycles( df, channel=0, fields=None ):\n",
    "    '''\n",
    "        df          : the sigproc_df from a run\n",
    "        channel     : (int) which channel to include\n",
    "        fields      : None, int, or list of ints, which field(s) to include\n",
    "        \n",
    "        Returns:\n",
    "            a vector of length n_cycles containing average signal at each cycle\n",
    "    '''\n",
    "    s = df[df.channel_i==channel]\n",
    "    if fields is not None:\n",
    "        if isinstance(fields,int):\n",
    "            fields=[fields]\n",
    "        s = s[s.field_i.isin(fields)]\n",
    "    avg_sig = s.groupby('cycle_i')['signal'].mean()\n",
    "    return np.array(avg_sig)\n",
    "\n",
    "def get_signal_xy( run, channel=0, fields=None ):\n",
    "    x = np.arange( run.sigproc.n_cycles )\n",
    "    y = average_signal_all_cycles( run.sigproc.fields__n_peaks__peaks__radmat(), channel=channel, fields=fields )\n",
    "    return x, y\n",
    "\n",
    "def single_exp( t, a1, b1, c ):\n",
    "    return a1 * np.exp(-b1*t) + c\n",
    "\n",
    "def double_exp( t, a1, b1, a2, b2, c ):\n",
    "    return a1 * np.exp(-b1*t) + a2 * np.exp(-b2*t) + c\n",
    "\n",
    "exp1_param_names = ['a1','b1','c']\n",
    "exp2_param_names = ['a1','b1', 'a2', 'b2', 'c']\n",
    "\n",
    "def guess_exp_params( x_values, y_values ):\n",
    "    '''\n",
    "    The difficulty with all fitting functions is that they often need\n",
    "    reasonable starting points to get anywhere!\n",
    "    \n",
    "    x_values, y_values: the data you hope to fit\n",
    "    \n",
    "    Returns:\n",
    "        p1,p2 - each vectors which are guesses for the exp1 and exp2 \n",
    "                functions to fit this data.            \n",
    "    '''    \n",
    "\n",
    "    six_halflives = 6.0 * np.log(2)\n",
    "    duration = x_values[-1] - x_values[0]\n",
    "    y0 = y_values[0]\n",
    "    yinf = y_values[-1]\n",
    "\n",
    "    # single-exp guesses\n",
    "    p1 = [ y0-yinf, six_halflives/duration, yinf ]\n",
    "    \n",
    "    # double-exp guesses\n",
    "    dt1 = duration // 6\n",
    "    dt2 = duration\n",
    "    ymid = y_values[dt1]\n",
    "    b1=six_halflives / dt1\n",
    "    b2=six_halflives / dt2\n",
    "    p2 = [y0-ymid,b1,ymid-yinf,b2,yinf]\n",
    "    \n",
    "    return p1,p2\n",
    "\n",
    "def wrapped_curve_fit( fitFn, x, y, p0, data_name='' ):\n",
    "    '''\n",
    "    Fit fitFn to data in x,y start at param vector p0.\n",
    "    Returns param vector, covariance matrix, or None if fit failed\n",
    "    for some reason (usually failure to converge)\n",
    "\n",
    "    data_name is optional  and use for error reporting in the case\n",
    "    of failed fits.\n",
    "    '''\n",
    "    try:\n",
    "        p,c = curve_fit( fitFn, x, y, p0=p0)\n",
    "    except:\n",
    "        print( f\"{data_name} {fitFn.__name__} fit failed (probably failed to converge)\")\n",
    "        p = c = None\n",
    "    return p,c\n",
    "\n",
    "# Put this into an easy form to get half-lives for signal for a given\n",
    "# field and channel for a run based on some exponential fit.\n",
    "#\n",
    "def get_halflife( run, field, channel, n_exponentials ):\n",
    "    '''\n",
    "    fit an exponential function with n_exponentials to data in field,channel, \n",
    "    and compute the halflife(s).\n",
    "    Returns:\n",
    "        a vector of the half-lifes (one for each exponential)\n",
    "    '''\n",
    "\n",
    "    assert 0 < n_exponentials < 3\n",
    "    fitFn = [None,single_exp, double_exp ][n_exponentials]\n",
    "    \n",
    "    x,y = get_signal_xy( run, channel=channel, fields=field )\n",
    "    p = None\n",
    "    \n",
    "    if len(y) >= 5:\n",
    "        exp1_guess_p, exp2_guess_p = guess_exp_params( x, y )\n",
    "        p0 = [None,exp1_guess_p, exp2_guess_p][n_exponentials]\n",
    "\n",
    "        p,c = wrapped_curve_fit( fitFn, x, y, p0, f\"field{field} ch{ch}\" )\n",
    "\n",
    "    if p is None:\n",
    "        # If fit failed for some reason\n",
    "        return [np.nan] * n_exponentials\n",
    "\n",
    "    # Half-life is function of rate param b1,b2, etc:\n",
    "    # p = a1,b1,c (single exp) or a1,b1,a2,b2,c (double exp) so --> bn = p[n*2 - 1]\n",
    "    \n",
    "    half_lives = []\n",
    "    for n in range(1,n_exponentials+1):\n",
    "        rate = p[n*2-1]\n",
    "        half_lives += [ np.log(2) / rate ]\n",
    "        \n",
    "    return half_lives\n",
    "    \n",
    "    \n",
    "\n",
    "##########################################################################################\n",
    "#\n",
    "# a. get data you want to fit - the decay of average signal\n",
    "# \n",
    "which_fields = 0  # None for all, or some int or list of fields\n",
    "which_channel = 0   # which channel to get signal for\n",
    "\n",
    "fields_label = \"All\" if which_fields is None else f\"{which_fields}\"\n",
    "data_name = f\"field:{fields_label} ch:{which_channel}\"\n",
    "\n",
    "test_x_values,test_y_values = get_signal_xy( run, which_channel, which_fields )\n",
    "\n",
    "if len(test_y_values) < 5: # need at least 5 datapoints for double exp fit.\n",
    "    print( f\"No data to fit in field {which_fields} channel {which_channel}\")\n",
    "\n",
    "else:\n",
    "\n",
    "    # b. fit it to a couple of functions.  Note to fit you often have to make\n",
    "    # reasonable guesses at the params, so if you know those (approximately),\n",
    "    # you can supply them here.  Sometimes the guesses aren't close enough \n",
    "    # and the fitter does not converge.  \n",
    "    #\n",
    "    exp1_guess_p, exp2_guess_p = guess_exp_params( test_x_values, test_y_values )\n",
    "\n",
    "    p_exp1,p_cov1 = wrapped_curve_fit( single_exp, test_x_values, test_y_values, exp1_guess_p, data_name )\n",
    "    p_exp2,p_cov2 = wrapped_curve_fit( double_exp, test_x_values, test_y_values, exp2_guess_p, data_name )\n",
    "\n",
    "    # c. evaluate functions at optimal params, print fitted params, and plot\n",
    "    #\n",
    "    if p_exp1 is not None:\n",
    "        exp1_eval = [ single_exp( t, p_exp1[0], p_exp1[1], p_exp1[2]) for t in test_x_values ]\n",
    "        print( '\\nSingle Exponential')\n",
    "        for name,value in zip( exp1_param_names, p_exp1):\n",
    "            print( f'{name:2s} {value}')\n",
    "        print(f\"\\nerr = {np.sqrt(np.diag(p_cov1))}\")\n",
    "        print(f\"sse = {np.linalg.norm(test_y_values-exp1_eval)}\")\n",
    "\n",
    "        with z( _merge=True, f_title=f'Signal, single exp: ch={which_channel} field={fields_label}',f_y_axis_label='average signal',f_x_axis_label='cycle' ):\n",
    "            z.line(x=test_x_values,y=exp1_eval,line_color='red',line_width=2)\n",
    "            z.scat(x=test_x_values,y=test_y_values,)\n",
    "\n",
    "    if p_exp2 is not None:\n",
    "        exp2_eval = [ double_exp( t, p_exp2[0], p_exp2[1], p_exp2[2], p_exp2[3], p_exp2[4]) for t in test_x_values ]\n",
    "        print( '\\nDouble Exponential')\n",
    "        for name,value in zip( exp2_param_names, p_exp2 ):\n",
    "            print( f'{name:2s} {value}')\n",
    "        print(f\"\\nerr = {np.sqrt(np.diag(p_cov2))}\")\n",
    "        print(f\"sse = {np.linalg.norm(test_y_values-exp2_eval)}\")\n",
    "\n",
    "        with z( _merge=True, f_title=f'Signal, double exp: ch={which_channel} field={fields_label}',f_y_axis_label='average signal',f_x_axis_label='cycle' ):\n",
    "            z.line(x=test_x_values,y=exp2_eval,line_color='red',line_width=2)\n",
    "            z.scat(x=test_x_values,y=test_y_values,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 3. Flat file for radiometry matrix (\"radmat\")\n",
    "#   \n",
    "# Grab the peak_i, channel, cycle, signal, noise, and field columns from the sigproc_df\n",
    "# and emit as a csv.  Sort by channel, peak_i, cycle to get all of the same peak contiguous.\n",
    "\n",
    "rad_export = run.sigproc.fields__n_peaks__peaks__radmat()[['channel_i','peak_i','cycle_i','field_i','signal','noise']].sort_values(['field_i','channel_i','peak_i','cycle_i'])\n",
    "filename = f'./report_peaks_{run.run_folder.basename}.csv'\n",
    "rad_export.to_csv( filename, index=False, float_format=\"%g\" )\n",
    "\n",
    "displays.md( f'## This table exported as {filename[2:]}')\n",
    "display( rad_export.head(5) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 4. Tabular output per nd2 file (per \"field\" for \"--movie\" timeseries captures)\n",
    "#\n",
    "# * File name, number_frames, time_per_frame (probably a setting present in the nd2?), number of spots identified,\n",
    "#   mean_early_brightness (1st frame), median_early_brightness (1st frame), stdev_early_brightness (1st frame), \n",
    "# . half_life_1exp (ln2/b; from single exponential fit), half_life_b1 (ln 2/b1), \n",
    "# . half_life_b2 (ln2/b2) [these two from two exponential fits]  \n",
    "\n",
    "# TODO: does the RunResult load manifest files?\n",
    "# assert run.nd2_import_movie.n_fields == len(run.nd2.manifest.nd2_paths)\n",
    "\n",
    "col_titles = [ \n",
    "    \"filename\", \"n_frames\", \"exposure_time\", \"n_peaks\", \"frame1_signal_mean\",\n",
    "    \"frame1_signal_median\", \"frame1_signal_stddev\", \"frames1t5_signal_mean\",\n",
    "    \"frames1t5_signal_median\", \"frames1t5_signal_stddev\", \"half_1exp\", \"half_2exp_b1\", \"half_2exp_b2\" ]\n",
    "\n",
    "\n",
    "s = run.sigproc.fields__n_peaks__peaks__radmat()\n",
    "field_meta = run.ims_import_movie.metadata_by_field()\n",
    "field_df = run.sigproc.fields()\n",
    "rows = []\n",
    "for field_i in range(run.ims_import_movie.n_fields):\n",
    "    meta = field_meta[field_meta.field_i == field_i]\n",
    "    df = field_df[(field_df.cycle_i==0)&(field_df.field_i==field_i)]\n",
    "    for ch in range(run.sigproc.n_channels):\n",
    "        row = Munch().fromkeys(col_titles)\n",
    "        row.filename = meta.filename.iloc[0]\n",
    "        row.n_frames = meta.n_frames.iloc[0]\n",
    "        row.exposure_time = df.exposure_time.iloc[0]\n",
    "        row.n_peaks = s[(s.cycle_i==0) & (s.field_i==field_i) & (s.channel_i==ch)].count().peak_i\n",
    "\n",
    "        mean,median,stddev,_,_,_ = get_signal_stats_for_cycles( s, cycle_start=0, n_cycles=1, channel=ch, fields=field_i )\n",
    "        row.frame1_signal_mean = mean\n",
    "        row.frame1_signal_median = median\n",
    "        row.frame1_signal_stddev = stddev\n",
    "\n",
    "        mean,median,stddev,_,_,_ = get_signal_stats_for_cycles( s, cycle_start=0, n_cycles=5, channel=ch, fields=field_i )\n",
    "        row.frames1t5_signal_mean = mean\n",
    "        row.frames1t5_signal_median = median\n",
    "        row.frames1t5_signal_stddev = stddev\n",
    "\n",
    "        row.half_1exp = get_halflife( run, field_i, ch, n_exponentials=1 )[0]\n",
    "        \n",
    "        halfs = get_halflife( run, field_i, ch, n_exponentials=2 )\n",
    "        row.half_2exp_b1 = halfs[0]\n",
    "        row.half_2exp_b2 = halfs[1]\n",
    "        \n",
    "        rows += [row]\n",
    "\n",
    "summary_df = pd.DataFrame( rows )\n",
    "filename = f'./report_nd2_{run.run_folder.basename}.csv'\n",
    "summary_export_df = summary_df[ col_titles ]  # force order of columns\n",
    "summary_export_df.to_csv( filename, index=False, float_format=\"%g\", na_rep=\"NaN\" )\n",
    "\n",
    "displays.md( f'## This table is exported as {filename[2:]}')\n",
    "display(summary_export_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal: Interactive Wizards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.wizard_scat_df(run, default_x='cycle_i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.wizard_xy_df(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile = 0.50\n",
    "max_bright = run.sigproc.fields__n_peaks__peaks__radmat().signal.quantile(percentile)\n",
    "stride = run.sigproc.n_cycles // 10 # display approx 10 frames from sequence\n",
    "plots.wizard_raw_images(run, show_circles=False, peak_i_square=True, square_radius=7, max_bright=max_bright, cycle_stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
